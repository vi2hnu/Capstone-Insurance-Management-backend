Attaching to apigateway, billingservice, claimsservice, configserver, emailservice, eureka, identityservice, kafkaQueue, mongo, policyservice, providerservice, redis, sqldb
configserver  | 
configserver  |   .   ____          _            __ _ _
configserver  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
configserver  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
configserver  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
configserver  |   '  |____| .__|_| |_|_| |_\__, | / / / /
configserver  |  =========|_|==============|___/=/_/_/_/
configserver  | 
configserver  |  :: Spring Boot ::                (v4.0.1)
configserver  | 
configserver  | 2026-01-04T16:51:09.883Z  INFO 1 --- [Config-Server] [           main] o.e.c.ConfigServerApplication            : Starting ConfigServerApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Config-Server-0.0.1-SNAPSHOT.jar started by root in /app)
configserver  | 2026-01-04T16:51:09.886Z  INFO 1 --- [Config-Server] [           main] o.e.c.ConfigServerApplication            : No active profile set, falling back to 1 default profile: "default"
configserver  | 2026-01-04T16:51:10.487Z  INFO 1 --- [Config-Server] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=36ee5bc3-b46f-32a1-99c6-6db240323d1c
configserver  | 2026-01-04T16:51:10.703Z  INFO 1 --- [Config-Server] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8888 (http)
configserver  | 2026-01-04T16:51:10.712Z  INFO 1 --- [Config-Server] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
configserver  | 2026-01-04T16:51:10.713Z  INFO 1 --- [Config-Server] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
configserver  | 2026-01-04T16:51:10.729Z  INFO 1 --- [Config-Server] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 779 ms
configserver  | 2026-01-04T16:51:11.560Z  INFO 1 --- [Config-Server] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8888 (http) with context path '/'
configserver  | 2026-01-04T16:51:11.588Z  INFO 1 --- [Config-Server] [           main] o.e.c.ConfigServerApplication            : Started ConfigServerApplication in 2.237 seconds (process running for 2.731)
configserver  | 2026-01-04T16:51:13.932Z  INFO 1 --- [Config-Server] [nio-8888-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
configserver  | 2026-01-04T16:51:13.932Z  INFO 1 --- [Config-Server] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
configserver  | 2026-01-04T16:51:13.933Z  INFO 1 --- [Config-Server] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
kafkaQueue    | ===> User
kafkaQueue    | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafkaQueue    | ===> Setting default values of environment variables if not already set.
kafkaQueue    | CLUSTER_ID not set. Setting it to default value: "5L6g3nShT-eMCtK--X86sw"
kafkaQueue    | ===> Configuring ...
kafkaQueue    | Running in KRaft mode...
kafkaQueue    | ===> Launching ... 
kafkaQueue    | ===> Using provided cluster id 5L6g3nShT-eMCtK--X86sw ...
redis         | Starting Redis Server
redis         | 1:C 04 Jan 2026 16:51:16.712 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis         | 1:C 04 Jan 2026 16:51:16.712 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis         | 1:C 04 Jan 2026 16:51:16.712 * Redis version=8.4.0, bits=64, commit=00000000, modified=1, pid=1, just started
redis         | 1:C 04 Jan 2026 16:51:16.712 * Configuration loaded
redis         | 1:M 04 Jan 2026 16:51:16.712 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis         | 1:M 04 Jan 2026 16:51:16.712 * monotonic clock: POSIX clock_gettime
redis         | 1:M 04 Jan 2026 16:51:16.713 * Running mode=standalone, port=6379.
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> RedisBloom version 8.4.0 (Git=unknown)
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> Registering configuration options: [
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> 	{ bf-error-rate       :      0.01 }
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> 	{ bf-initial-size     :       100 }
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> 	{ bf-expansion-factor :         2 }
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> 	{ cf-bucket-size      :         2 }
redis         | 1:M 04 Jan 2026 16:51:16.715 * <bf> 	{ cf-initial-size     :      1024 }
redis         | 1:M 04 Jan 2026 16:51:16.716 * <bf> 	{ cf-max-iterations   :        20 }
redis         | 1:M 04 Jan 2026 16:51:16.716 * <bf> 	{ cf-expansion-factor :         1 }
redis         | 1:M 04 Jan 2026 16:51:16.716 * <bf> 	{ cf-max-expansions   :        32 }
redis         | 1:M 04 Jan 2026 16:51:16.716 * <bf> ]
redis         | 1:M 04 Jan 2026 16:51:16.716 * Module 'bf' loaded from /usr/local/lib/redis/modules//redisbloom.so
redis         | 1:M 04 Jan 2026 16:51:16.731 * <search> Redis version found by RedisSearch : 8.4.0 - oss
redis         | 1:M 04 Jan 2026 16:51:16.731 * <search> RediSearch version 8.4.2 (Git=9e2b676)
redis         | 1:M 04 Jan 2026 16:51:16.731 * <search> Low level api version 1 initialized successfully
redis         | 1:M 04 Jan 2026 16:51:16.731 * <search> gc: ON, prefix min length: 2, min word length to stem: 4, prefix max expansions: 200, query timeout (ms): 500, timeout policy: return, oom policy: return, cursor read size: 1000, cursor max idle (ms): 300000, max doctable size: 1000000, max number of search results:  1000000, default scorer: BM25STD, 
redis         | 1:M 04 Jan 2026 16:51:16.732 * <search> Initialized thread pools!
redis         | 1:M 04 Jan 2026 16:51:16.732 * <search> Disabled workers threadpool of size 0
redis         | 1:M 04 Jan 2026 16:51:16.732 * <search> Subscribe to config changes
redis         | 1:M 04 Jan 2026 16:51:16.732 * <search> Subscribe to cluster slot migration events
redis         | 1:M 04 Jan 2026 16:51:16.732 * <search> Enabled role change notification
redis         | 1:M 04 Jan 2026 16:51:16.733 * <search> Cluster configuration: AUTO partitions, type: 0, coordinator timeout: 0ms
redis         | 1:M 04 Jan 2026 16:51:16.733 * <search> Register write commands
redis         | 1:M 04 Jan 2026 16:51:16.733 * Module 'search' loaded from /usr/local/lib/redis/modules//redisearch.so
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> RedisTimeSeries version 80400, git_sha=3520a1568ad69076d60885c70711fbdc9b448749
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> Redis version found by RedisTimeSeries : 8.4.0 - oss
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> Registering configuration options: [
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-compaction-policy   :              }
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-num-threads         :            3 }
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-retention-policy    :            0 }
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-duplicate-policy    :        block }
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-chunk-size-bytes    :         4096 }
redis         | 1:M 04 Jan 2026 16:51:16.739 * <timeseries> 	{ ts-encoding            :   compressed }
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> 	{ ts-ignore-max-time-diff:            0 }
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> 	{ ts-ignore-max-val-diff :     0.000000 }
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> ]
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> Detected redis oss
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> Subscribe to ASM events
redis         | 1:M 04 Jan 2026 16:51:16.740 * <timeseries> Enabled diskless replication
redis         | 1:M 04 Jan 2026 16:51:16.740 * Module 'timeseries' loaded from /usr/local/lib/redis/modules//redistimeseries.so
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Created new data type 'ReJSON-RL'
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> version: 80400 git sha: unknown branch: unknown
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V1 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V2 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V3 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V4 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V5 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Exported RedisJSON_V6 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Enabled diskless replication
redis         | 1:M 04 Jan 2026 16:51:16.747 * <ReJSON> Initialized shared string cache, thread safe: true.
redis         | 1:M 04 Jan 2026 16:51:16.747 * Module 'ReJSON' loaded from /usr/local/lib/redis/modules//rejson.so
redis         | 1:M 04 Jan 2026 16:51:16.747 * <search> Acquired RedisJSON_V6 API
redis         | 1:M 04 Jan 2026 16:51:16.747 * Server initialized
redis         | 1:M 04 Jan 2026 16:51:16.747 * Ready to accept connections tcp
sqldb         | 2026-01-04 16:51:16+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 9.5.0-1.el9 started.
mongo         | {"t":{"$date":"2026-01-04T16:51:17.181+00:00"},"s":"I",  "c":"-",        "id":8991200, "ctx":"main","msg":"Shuffling initializers","attr":{"seed":1882554911}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.195+00:00"},"s":"I",  "c":"CONTROL",  "id":97374,   "ctx":"main","msg":"Automatically disabling TLS 1.0 and TLS 1.1, to force-enable TLS 1.1 specify --sslDisabledProtocols 'TLS1_0'; to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.197+00:00"},"s":"I",  "c":"NETWORK",  "id":4915701, "ctx":"main","msg":"Initialized wire specification","attr":{"spec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":27},"incomingInternalClient":{"minWireVersion":0,"maxWireVersion":27},"outgoing":{"minWireVersion":6,"maxWireVersion":27},"isInternalClient":true}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.199+00:00"},"s":"I",  "c":"CONTROL",  "id":5945603, "ctx":"main","msg":"Multi threading initialized"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.199+00:00"},"s":"I",  "c":"CONTROL",  "id":4615611, "ctx":"initandlisten","msg":"MongoDB starting","attr":{"pid":1,"port":27017,"dbPath":"/data/db","architecture":"64-bit","host":"27dafe81402e"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.199+00:00"},"s":"I",  "c":"CONTROL",  "id":23403,   "ctx":"initandlisten","msg":"Build Info","attr":{"buildInfo":{"version":"8.2.2","gitVersion":"594f839ceec1f4385be9a690131412d67b249a0a","openSSLVersion":"OpenSSL 3.0.13 30 Jan 2024","modules":[],"allocator":"tcmalloc-google","environment":{"distmod":"ubuntu2404","distarch":"x86_64","target_arch":"x86_64"}}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.199+00:00"},"s":"I",  "c":"CONTROL",  "id":51765,   "ctx":"initandlisten","msg":"Operating System","attr":{"os":{"name":"Ubuntu","version":"24.04"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.199+00:00"},"s":"I",  "c":"CONTROL",  "id":21951,   "ctx":"initandlisten","msg":"Options set by command line","attr":{"options":{"net":{"bindIp":"*"},"security":{"authorization":"enabled"}}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.212+00:00"},"s":"I",  "c":"NETWORK",  "id":4648601, "ctx":"initandlisten","msg":"Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set at least one of the related parameters","attr":{"relatedParameters":["tcpFastOpenServer","tcpFastOpenClient","tcpFastOpenQueueSize"]}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.214+00:00"},"s":"W",  "c":"STORAGE",  "id":22271,   "ctx":"initandlisten","msg":"Detected unclean shutdown - Lock file is not empty","attr":{"lockFile":"/data/db/mongod.lock"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.214+00:00"},"s":"I",  "c":"STORAGE",  "id":22270,   "ctx":"initandlisten","msg":"Storage engine to use detected by data files","attr":{"dbpath":"/data/db","storageEngine":"wiredTiger"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.214+00:00"},"s":"W",  "c":"STORAGE",  "id":22302,   "ctx":"initandlisten","msg":"Recovering data from the last clean checkpoint."}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.215+00:00"},"s":"I",  "c":"STORAGE",  "id":22315,   "ctx":"initandlisten","msg":"Opening WiredTiger","attr":{"config":"create,cache_size=7311M,session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,remove=true,path=journal,compressor=snappy),builtin_extension_config=(zstd=(compression_level=6)),file_manager=(close_idle_time=600,close_scan_interval=10,close_handle_minimum=2000),statistics_log=(wait=0),json_output=(error,message),verbose=[recovery_progress:1,checkpoint_progress:1,compact_progress:1,live_restore_progress:1,backup:0,checkpoint:0,compact:0,eviction:0,fileops:0,history_store:0,live_restore:0,recovery:0,rts:0,salvage:0,tiered:0,timestamp:0,transaction:0,verify:0,log:0],prefetch=(available=true,default=false),"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.227+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":226916,"thread":"1:0x7f0f46466400","session_name":"wiredtiger_open","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"opening the WiredTiger library"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.260+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":259986,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"connection configuration string parsing completed"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.261+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":261873,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting WiredTiger utility threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.271+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":271443,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting WiredTiger recovery"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.272+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":272210,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Recovering log 42 through 43"}}}
sqldb         | 2026-01-04 16:51:17+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
sqldb         | 2026-01-04 16:51:17+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 9.5.0-1.el9 started.
mongo         | {"t":{"$date":"2026-01-04T16:51:17.447+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":447022,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Recovering log 43 through 43"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.662+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":662333,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"scanning metadata to find the largest file ID"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.663+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":663620,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"largest file ID found in the metadata 28"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.664+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":664861,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"Main recovery loop: starting at 42,5760 to 43,256"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.665+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":665108,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting eviction threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.666+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":666211,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Recovering log 42 through 43"}}}
sqldb         | '/var/lib/mysql/mysql.sock' -> '/var/run/mysqld/mysqld.sock'
mongo         | {"t":{"$date":"2026-01-04T16:51:17.830+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":830083,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Recovering log 43 through 43"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.939+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":939788,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery log replay has successfully finished and ran for 668 milliseconds"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.939+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":939904,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Set global recovery timestamp: (0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.939+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":939926,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Set global oldest timestamp: (0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.939+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":939964,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"[RECOVERY_RTS] performing recovery rollback_to_stable with stable_timestamp=(0, 0) and oldest_timestamp=(0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.941+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":941045,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery rollback to stable has successfully finished and ran for 1 milliseconds"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.941+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":941140,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"stopping eviction threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.941+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":941164,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"waiting for eviction threads to stop"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.941+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"thread8","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":941205,"thread":"1:0x7f0f4243c6c0","session_name":"eviction-server","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"eviction thread exiting"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.944+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":944053,"thread":"1:0x7f0f46466400","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT","log_id":1000000,"category_id":5,"verbose_level":"INFO","verbose_level_id":0,"msg":"Checkpoint requested at stable timestamp (0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.945+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":944992,"thread":"1:0x7f0f46466400","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 4, snapshot max: 4 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.954+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":953972,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery checkpoint has successfully finished and ran for 12 milliseconds"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.954+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":954162,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1493201,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery was completed successfully and took 682ms, including 668ms for the log replay, 1ms for the rollback to stable, and 12ms for the checkpoint."}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.954+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":954220,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1493201,"category_id":33,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery was completed successfully and took 682ms, including 668ms for the log replay, 1ms for the rollback to stable, and 12ms for the checkpoint."}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.956+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":956020,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting eviction threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.957+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":957671,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"WiredTiger utility threads started successfully"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.957+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":957756,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"the WiredTiger library has successfully opened"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.957+00:00"},"s":"I",  "c":"STORAGE",  "id":4795906, "ctx":"initandlisten","msg":"WiredTiger opened","attr":{"durationMillis":742}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.957+00:00"},"s":"I",  "c":"RECOVERY", "id":23987,   "ctx":"initandlisten","msg":"WiredTiger recoveryTimestamp","attr":{"recoveryTimestamp":{"$timestamp":{"t":0,"i":0}}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.957+00:00"},"s":"I",  "c":"STORAGE",  "id":9086700, "ctx":"initandlisten","msg":"WiredTiger session cache max value has been set","attr":{"sessionCacheMax":16500}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.958+00:00"},"s":"I",  "c":"STORAGE",  "id":10158000,"ctx":"initandlisten","msg":"Opening spill WiredTiger","attr":{"config":"create,cache_size=391M,session_max=1024,eviction=(threads_min=1,threads_max=1),eviction_dirty_target=19MB,eviction_dirty_trigger=312MB,eviction_updates_trigger=312MB,config_base=false,statistics=(fast),log=(enabled=false),builtin_extension_config=(zstd=(compression_level=-7)),file_manager=(close_idle_time=600,close_scan_interval=10,close_handle_minimum=2000),statistics_log=(wait=0),json_output=(error,message),verbose=[recovery_progress:1,checkpoint_progress:1,compact_progress:1,live_restore_progress:1,backup:0,checkpoint:0,compact:0,eviction:0,fileops:0,history_store:0,live_restore:0,recovery:0,rts:0,salvage:0,tiered:0,timestamp:0,transaction:0,verify:0,log:0],"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.961+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":961104,"thread":"1:0x7f0f46466400","session_name":"wiredtiger_open","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"opening the WiredTiger library"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.963+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":963335,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"connection configuration string parsing completed"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.969+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":969195,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting WiredTiger utility threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.969+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":969560,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting WiredTiger recovery"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.969+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":969858,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"scanning metadata to find the largest file ID"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.969+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":969935,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"largest file ID found in the metadata 0"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.970+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":969983,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery log replay has successfully finished and ran for 0 milliseconds"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.970+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":970019,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Set global recovery timestamp: (0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.970+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":970045,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1000000,"category_id":33,"verbose_level":"DEBUG_1","verbose_level_id":1,"msg":"Set global oldest timestamp: (0, 0)"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.970+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":970120,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY","log_id":1493201,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery was completed successfully and took 0ms, including 0ms for the log replay, 0ms for the rollback to stable, and 0ms for the checkpoint."}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.970+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":970165,"thread":"1:0x7f0f46466400","session_name":"txn-recover","category":"WT_VERB_RECOVERY_PROGRESS","log_id":1493201,"category_id":33,"verbose_level":"INFO","verbose_level_id":0,"msg":"recovery was completed successfully and took 0ms, including 0ms for the log replay, 0ms for the rollback to stable, and 0ms for the checkpoint."}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.984+00:00"},"s":"I",  "c":"WTEVICT",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":984284,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_EVICTION","log_id":1000000,"category_id":15,"verbose_level":"INFO","verbose_level_id":0,"msg":"starting eviction threads"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.985+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":985032,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"WiredTiger utility threads started successfully"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.985+00:00"},"s":"I",  "c":"WTRECOV",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545477,"ts_usec":985126,"thread":"1:0x7f0f46466400","session_name":"connection","category":"WT_VERB_RECOVERY","log_id":1000000,"category_id":32,"verbose_level":"INFO","verbose_level_id":0,"msg":"the WiredTiger library has successfully opened"}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.985+00:00"},"s":"I",  "c":"STORAGE",  "id":10158001,"ctx":"initandlisten","msg":"Spill WiredTiger opened","attr":{"durationMillis":27}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.986+00:00"},"s":"I",  "c":"STORAGE",  "id":9529901, "ctx":"initandlisten","msg":"Initializing durable catalog","attr":{"numRecords":8}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.988+00:00"},"s":"I",  "c":"STORAGE",  "id":9529902, "ctx":"initandlisten","msg":"Retrieving all idents from storage engine"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.988+00:00"},"s":"I",  "c":"STORAGE",  "id":9529903, "ctx":"initandlisten","msg":"Initializing all collections in durable catalog","attr":{"numEntries":8}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.990+00:00"},"s":"W",  "c":"CONTROL",  "id":22184,   "ctx":"initandlisten","msg":"Soft rlimits for open file descriptors too low","attr":{"currentValue":1024,"recommendedMinimum":64000},"tags":["startupWarnings"]}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.990+00:00"},"s":"W",  "c":"CONTROL",  "id":9068900, "ctx":"initandlisten","msg":"For customers running the current memory allocator, we suggest changing the contents of the following sysfsFile","attr":{"allocator":"tcmalloc-google","sysfsFile":"/sys/kernel/mm/transparent_hugepage/enabled","currentValue":"never","desiredValue":"always"},"tags":["startupWarnings"]}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.991+00:00"},"s":"W",  "c":"CONTROL",  "id":9068900, "ctx":"initandlisten","msg":"For customers running the current memory allocator, we suggest changing the contents of the following sysfsFile","attr":{"allocator":"tcmalloc-google","sysfsFile":"/sys/kernel/mm/transparent_hugepage/defrag","currentValue":"madvise","desiredValue":"defer+madvise"},"tags":["startupWarnings"]}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.991+00:00"},"s":"W",  "c":"CONTROL",  "id":8640302, "ctx":"initandlisten","msg":"We suggest setting the contents of sysfsFile to 0.","attr":{"sysfsFile":"/sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none","currentValue":511},"tags":["startupWarnings"]}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.991+00:00"},"s":"W",  "c":"CONTROL",  "id":8386700, "ctx":"initandlisten","msg":"We suggest setting swappiness to 0 or 1, as swapping can cause performance problems.","attr":{"sysfsFile":"/proc/sys/vm/swappiness","currentValue":10},"tags":["startupWarnings"]}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.994+00:00"},"s":"I",  "c":"NETWORK",  "id":4915702, "ctx":"initandlisten","msg":"Updated wire specification","attr":{"oldSpec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":27},"incomingInternalClient":{"minWireVersion":0,"maxWireVersion":27},"outgoing":{"minWireVersion":6,"maxWireVersion":27},"isInternalClient":true},"newSpec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":27},"incomingInternalClient":{"minWireVersion":27,"maxWireVersion":27},"outgoing":{"minWireVersion":27,"maxWireVersion":27},"isInternalClient":true}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.994+00:00"},"s":"I",  "c":"REPL",     "id":5853300, "ctx":"initandlisten","msg":"current featureCompatibilityVersion value","attr":{"featureCompatibilityVersion":"8.2","context":"startup"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.994+00:00"},"s":"I",  "c":"STORAGE",  "id":5071100, "ctx":"initandlisten","msg":"Clearing temp directory"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.994+00:00"},"s":"I",  "c":"STORAGE",  "id":10682200,"ctx":"initandlisten","msg":"Dropping spill idents","attr":{"numIdents":0}}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.995+00:00"},"s":"I",  "c":"CONTROL",  "id":6608200, "ctx":"initandlisten","msg":"Initializing cluster server parameters from disk"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.995+00:00"},"s":"I",  "c":"CONTROL",  "id":20536,   "ctx":"initandlisten","msg":"Flow Control is enabled on this deployment"}
mongo         | {"t":{"$date":"2026-01-04T16:51:17.995+00:00"},"s":"I",  "c":"FTDC",     "id":20625,   "ctx":"initandlisten","msg":"Initializing full-time diagnostic data capture","attr":{"dataDirectory":"/data/db/diagnostic.data"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.000+00:00"},"s":"I",  "c":"REPL",     "id":6015317, "ctx":"initandlisten","msg":"Setting new configuration state","attr":{"newState":"ConfigReplicationDisabled","oldState":"ConfigPreStart"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.001+00:00"},"s":"I",  "c":"STORAGE",  "id":22262,   "ctx":"initandlisten","msg":"Timestamp monitor starting"}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.002+00:00"},"s":"I",  "c":"STORAGE",  "id":7333401, "ctx":"initandlisten","msg":"Starting the DiskSpaceMonitor"}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.004+00:00"},"s":"I",  "c":"NETWORK",  "id":23015,   "ctx":"listener","msg":"Listening on","attr":{"address":"/tmp/mongodb-27017.sock"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.004+00:00"},"s":"I",  "c":"NETWORK",  "id":23015,   "ctx":"listener","msg":"Listening on","attr":{"address":"0.0.0.0:27017"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.004+00:00"},"s":"I",  "c":"NETWORK",  "id":23016,   "ctx":"listener","msg":"Waiting for connections","attr":{"port":27017,"ssl":"off"}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.004+00:00"},"s":"I",  "c":"CONTROL",  "id":8423403, "ctx":"initandlisten","msg":"mongod startup complete","attr":{"Summary of time elapsed":{"Startup from clean shutdown?":false,"Statistics":{"setUpPeriodicRunnerMillis":0,"setUpOCSPMillis":0,"setUpTransportLayerMillis":12,"initSyncCrashRecoveryMillis":0,"createLockFileMillis":0,"getStorageEngineMetadataMillis":0,"validateMetadataMillis":0,"createStorageEngineMillis":774,"writePIDMillis":0,"initializeFCVForIndexMillis":3,"dropAbandonedIdentsMillis":0,"standaloneClusterParamsMillis":0,"userAndRolesGraphMillis":0,"createSystemUsersIndexMillis":0,"waitForMajorityServiceMillis":0,"startUpReplCoordMillis":3,"recoverChangeStreamMillis":0,"logStartupOptionsMillis":0,"startUpTransportLayerMillis":1,"initAndListenTotalMillis":805}}}}
mongo         | {"t":{"$date":"2026-01-04T16:51:18.033+00:00"},"s":"I",  "c":"FTDC",     "id":20631,   "ctx":"ftdc","msg":"Unclean full-time diagnostic data capture shutdown detected, found interim file, some metrics may have been lost","attr":{"error":{"code":0,"codeName":"OK"}}}
kafkaQueue    | Log directory /tmp/kafka-logs is already formatted. Use --ignore-formatted to ignore this directory and format the others.
kafkaQueue    | [2026-01-04 16:51:19,546] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
kafkaQueue    | [2026-01-04 16:51:19,634] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafkaQueue    | [2026-01-04 16:51:19,635] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,712] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafkaQueue    | [2026-01-04 16:51:19,731] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafkaQueue    | [2026-01-04 16:51:19,732] INFO CONTROLLER: resolved wildcard host to kafkaQueue (org.apache.kafka.metadata.ListenerInfo)
kafkaQueue    | [2026-01-04 16:51:19,736] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2026-01-04 16:51:19,738] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafkaQueue    | [2026-01-04 16:51:19,757] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __cluster_metadata-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:19,758] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,758] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,758] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,785] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 505 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:19,788] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 505 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,788] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 505 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,790] INFO [ProducerStateManager partition=__cluster_metadata-0] Loading producer state from snapshot file 'SnapshotFile(offset=505, file=/tmp/kafka-logs/__cluster_metadata-0/00000000000000000505.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:19,792] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 505 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:19,797] INFO Initialized snapshots with IDs SortedSet() from /tmp/kafka-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafkaQueue    | [2026-01-04 16:51:19,802] INFO [raft-expiration-reaper]: Starting (org.apache.kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,804] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,813] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafkaQueue/172.21.0.3:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,815] INFO [RaftManager id=1] Starting request manager with static voters: [kafkaQueue:9093 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,825] INFO [RaftManager id=1] Attempting durable transition to ResignedState(localId=1, epoch=1, voters=[1], electionTimeoutMs=1961, unackedVoters=[], preferredSuccessors=[]) from null (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,829] INFO [RaftManager id=1] Completed transition to ResignedState(localId=1, epoch=1, voters=[1], electionTimeoutMs=1961, unackedVoters=[], preferredSuccessors=[]) from null (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,831] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=1, leaderId=OptionalInt[1], votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1350, highWatermark=Optional.empty) from ResignedState(localId=1, epoch=1, voters=[1], electionTimeoutMs=1961, unackedVoters=[], preferredSuccessors=[]) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,831] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=fNoJ_7VGW2b68v1yqB4-vA, epoch=2, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1453) from ProspectiveState(epoch=1, leaderId=OptionalInt[1], votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1350, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,834] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=fNoJ_7VGW2b68v1yqB4-vA, epoch=2, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1453) from ProspectiveState(epoch=1, leaderId=OptionalInt[1], votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1350, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,836] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=fNoJ_7VGW2b68v1yqB4-vA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafkaQueue/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=2, epochStartOffset=505, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=fNoJ_7VGW2b68v1yqB4-vA, epoch=2, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1453) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,839] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=fNoJ_7VGW2b68v1yqB4-vA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafkaQueue/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=2, epochStartOffset=505, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=fNoJ_7VGW2b68v1yqB4-vA, epoch=2, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1453) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2026-01-04 16:51:19,845] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafkaQueue    | [2026-01-04 16:51:19,845] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
kafkaQueue    | [2026-01-04 16:51:19,849] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,849] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,850] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,852] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=506, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=33292)]) for the first time for epoch 2 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=506, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=33292)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
kafkaQueue    | [2026-01-04 16:51:19,858] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,858] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,858] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,859] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@343685591 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,859] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,859] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@847152178 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,860] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@847152178 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,861] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@343685591 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2026-01-04 16:51:19,862] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 0, but the high water mark is 506 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,862] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,877] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,888] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 506 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,890] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,890] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,891] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2026-01-04 16:51:19,891] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,892] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,894] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2026-01-04 16:51:19,902] INFO [ControllerServer id=1] Loaded new metadata FinalizedFeatures[metadataVersion=4.1-IV1, finalizedFeatures={group.version=1, transaction.version=2, eligible.leader.replicas.version=1, metadata.version=27}, finalizedFeaturesEpoch=505]. (org.apache.kafka.metadata.publisher.FeaturesPublisher)
kafkaQueue    | [2026-01-04 16:51:19,902] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,902] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,902] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,902] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [ControllerRegistrationManager id=1 incarnation=pj2Cvu0vRAqrEq5W0S9M2Q] Found registration for 3EZF3qI4SZeQ2qiHewNP9w instead of our incarnation. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2026-01-04 16:51:19,903] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,904] INFO [ControllerRegistrationManager id=1 incarnation=pj2Cvu0vRAqrEq5W0S9M2Q] initialized channel manager. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2026-01-04 16:51:19,905] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:19,905] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:19,906] INFO [DynamicConfigPublisher controller id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2026-01-04 16:51:19,909] INFO [ControllerRegistrationManager id=1 incarnation=pj2Cvu0vRAqrEq5W0S9M2Q] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=pj2Cvu0vRAqrEq5W0S9M2Q, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='kafkaQueue', port=9093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1)]) (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2026-01-04 16:51:19,911] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2026-01-04 16:51:19,911] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,912] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,914] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,915] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2026-01-04 16:51:19,922] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,923] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,924] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,925] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,927] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,928] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 505 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:19,928] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:19,928] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:19,930] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,931] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,935] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2026-01-04 16:51:19,947] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafkaQueue    | [2026-01-04 16:51:19,950] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafkaQueue    | [2026-01-04 16:51:19,952] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,953] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,955] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,955] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,957] INFO [ExpirationReaper-1-Produce]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,958] INFO [ExpirationReaper-1-Fetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,959] INFO [ExpirationReaper-1-DeleteRecords]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,959] INFO [ExpirationReaper-1-RemoteFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,960] INFO [ExpirationReaper-1-RemoteListOffsets]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,960] INFO [ExpirationReaper-1-ShareFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,964] INFO [ControllerRegistrationManager id=1 incarnation=pj2Cvu0vRAqrEq5W0S9M2Q] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2026-01-04 16:51:19,966] INFO [ControllerRegistrationManager id=1 incarnation=pj2Cvu0vRAqrEq5W0S9M2Q] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2026-01-04 16:51:19,967] INFO [share-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2026-01-04 16:51:19,973] INFO [share-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2026-01-04 16:51:19,975] INFO [persister-state-manager-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2026-01-04 16:51:19,976] INFO [PersisterStateManager]: Starting (org.apache.kafka.server.share.persister.PersisterStateManager$SendThread)
kafkaQueue    | [2026-01-04 16:51:19,976] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2026-01-04 16:51:19,978] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2026-01-04 16:51:19,978] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2026-01-04 16:51:19,979] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2026-01-04 16:51:19,979] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2026-01-04 16:51:19,986] INFO Unable to read the broker epoch in /tmp/kafka-logs. (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:19,986] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2026-01-04 16:51:19,987] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
configserver  | 2026-01-04T16:51:19.988Z  INFO 1 --- [Config-Server] [nio-8888-exec-2] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Service-Registry.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
kafkaQueue    | [2026-01-04 16:51:19,989] INFO [BrokerLifecycleManager id=1] Incarnation nkyhE6JWQNG_59KJ9mubJw of broker 1 in cluster 5L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:19,991] INFO [share-group-lock-timeout-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2026-01-04 16:51:19,992] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2026-01-04 16:51:19,996] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:20,002] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:20,002] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:20,002] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:20,003] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 506 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:20,004] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 506 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2026-01-04 16:51:20,006] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch[offset=506, epoch=2] with metadata.version Optional[4.1-IV1]. (kafka.server.metadata.BrokerMetadataPublisher)
kafkaQueue    | [2026-01-04 16:51:20,008] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,013] INFO Recovering 58 logs from /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,020] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for account-activation-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,020] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for payout-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,021] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,026] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,026] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,026] INFO [LogLoader partition=account-activation-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,026] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,027] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,027] INFO [LogLoader partition=payout-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,038] INFO Completed load of Log(dir=/tmp/kafka-logs/account-activation-email-0, topicId=YMHd0qiqSVKiOHPnYHQtTg, topic=account-activation-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (1/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,039] INFO Completed load of Log(dir=/tmp/kafka-logs/payout-email-0, topicId=26UsenmERCWALhrv0t9hYg, topic=payout-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (2/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,041] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for policy-purchase-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,041] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,041] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,041] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for claim-submission-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,041] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,042] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,042] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,043] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,045] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,045] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,046] INFO [LogLoader partition=policy-purchase-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,047] INFO Completed load of Log(dir=/tmp/kafka-logs/policy-purchase-email-0, topicId=MLAFZLQkTpu91l_pXrkO4g, topic=policy-purchase-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,049] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for policy-renewal-reminder-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,050] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,050] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,050] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,051] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,051] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,051] INFO [LogLoader partition=claim-submission-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,053] INFO Completed load of Log(dir=/tmp/kafka-logs/claim-submission-email-0, topicId=S0dlzdOMQbimXDtw99eBuA, topic=claim-submission-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (4/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,056] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for claim-decision-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,057] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,057] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,057] INFO [LogLoader partition=policy-renewal-reminder-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,057] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,057] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,058] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,058] INFO Completed load of Log(dir=/tmp/kafka-logs/policy-renewal-reminder-0, topicId=Qp03QJV5QSWTPX9t-KRo9Q, topic=policy-renewal-reminder, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (5/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,060] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for otp-email-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,060] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,061] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,061] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,062] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,063] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,063] INFO [LogLoader partition=claim-decision-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,064] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,064] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,064] INFO [LogLoader partition=otp-email-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,064] INFO Completed load of Log(dir=/tmp/kafka-logs/claim-decision-email-0, topicId=p62VaZAHSSWR-u7vWpOxHQ, topic=claim-decision-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (6/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,065] INFO Completed load of Log(dir=/tmp/kafka-logs/otp-email-0, topicId=KPJ-xKZjT4ecvZa7fAhK6A, topic=otp-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,067] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-46. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,067] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-13. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,068] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,074] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,074] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,074] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,076] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-13, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (8/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,076] INFO [ProducerStateManager partition=__consumer_offsets-46] Wrote producer snapshot at offset 9 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:20,077] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 9 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,077] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 9 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,077] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'SnapshotFile(offset=9, file=/tmp/kafka-logs/__consumer_offsets-46/00000000000000000009.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:20,077] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 9 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,079] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=9) with 1 segments, local-log-start-offset 0 and log-end-offset 9 in 13ms (9/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,079] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-9. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,079] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,079] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,079] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,080] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-42. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,081] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,081] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,081] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,085] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,086] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,086] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,086] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,086] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,086] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,087] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-42, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (10/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,088] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (11/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,089] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-21. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,089] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,089] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,089] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,090] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-17. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,091] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,092] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,092] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,093] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,093] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,093] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,094] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (12/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,096] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-30. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,096] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,097] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,097] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,097] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,097] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,097] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,098] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (13/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,102] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-26. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,102] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,102] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,102] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,103] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,103] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,103] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,103] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-30, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (14/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,105] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-5. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,106] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,106] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,106] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,108] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,109] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,109] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,110] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,110] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-26, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (15/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,111] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,111] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,112] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (16/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,113] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-1. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,114] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-38. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,114] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,114] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,114] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,115] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,115] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,115] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,120] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,121] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,121] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,121] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,121] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,122] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,123] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-1, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (17/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,124] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-38, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (18/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,126] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-34. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,127] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,127] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,127] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,128] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-16. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,129] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,129] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,129] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,134] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,134] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,134] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,134] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,134] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,135] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,137] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (19/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,137] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (20/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,139] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-45. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,139] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,139] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,139] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,141] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-12. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,142] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,143] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,143] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,145] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,145] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,145] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,147] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (21/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,149] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-41. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,150] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,152] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-12, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (22/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,154] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,154] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,155] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,156] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (23/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,156] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-24. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,157] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,157] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,157] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,160] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-20. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,161] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,161] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,161] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,163] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,163] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,163] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,166] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-24, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (24/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,166] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,167] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,167] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,169] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-49. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,169] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-20, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (25/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,170] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,170] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,170] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,173] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,174] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,174] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,174] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,177] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,177] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,177] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,178] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,178] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,178] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,180] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-49, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (26/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,180] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-0, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (27/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,182] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-25. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,183] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,183] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,183] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,184] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-29. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,184] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,184] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,184] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,188] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,189] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,189] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,190] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,190] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,190] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,190] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-25, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (28/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,191] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (29/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,193] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-8. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,194] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,194] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,194] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-37. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,194] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,197] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,197] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,198] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,200] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,200] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,201] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,202] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-8, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (30/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,203] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,203] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,203] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,204] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-37, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (31/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,205] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-4. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,205] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-33. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,205] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,205] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,205] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,206] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,206] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,206] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,209] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,209] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,209] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,211] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (32/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,212] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,212] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,212] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,213] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-15. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,214] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,214] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (33/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,214] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,214] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,218] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-48. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,219] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,219] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,219] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,220] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,220] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,220] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,222] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (34/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-11. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,227] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,228] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,229] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-48, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (35/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,233] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-44. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,234] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,234] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,234] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,234] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,234] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,235] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,237] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (36/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-23. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,240] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,241] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,241] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-44, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (37/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,244] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-19. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,244] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,245] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,245] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,247] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,248] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,248] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,250] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (38/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,253] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-32. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,254] INFO [ProducerStateManager partition=__consumer_offsets-19] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:20,254] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,254] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,254] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,255] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,256] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,256] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafkaQueue    | [2026-01-04 16:51:20,257] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 3 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,259] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-19, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 16ms (39/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,261] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,261] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,261] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,261] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-28. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,262] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,262] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,262] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,262] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-32, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (40/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,266] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-7. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,266] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,266] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,266] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,268] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,269] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,269] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,270] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (41/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,272] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,272] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,272] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,273] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-40. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,273] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,274] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,274] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,274] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-7, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (42/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,277] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-3. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,277] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,278] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,278] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,279] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,279] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,279] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,281] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (43/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,283] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,283] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,283] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,284] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-36. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,285] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,285] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,285] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,285] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (44/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,288] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-47. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,288] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,289] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,289] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,291] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,291] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,291] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,293] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-36, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (45/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,294] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-14. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,295] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,297] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (46/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,300] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,300] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,301] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,301] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-43. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,301] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,302] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,302] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-14, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (47/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,302] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,304] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-10. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,305] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,305] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,305] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,309] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,310] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (48/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,310] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-43, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (49/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,312] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-22. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,312] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,312] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,312] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,312] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-18. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,313] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,313] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,313] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,315] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,315] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,315] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,316] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (50/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,317] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-31. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,318] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,319] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-18, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (51/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,321] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,321] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,321] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,322] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-27. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,322] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-31, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (52/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,322] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,322] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,322] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,324] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-39. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,324] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,324] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,324] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,327] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,327] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,327] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,328] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,328] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,328] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,328] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (53/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,329] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (54/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-6. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-35. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,330] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,334] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,335] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (55/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,335] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-6, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (56/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,337] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for __consumer_offsets-2. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,337] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0 recovered for claim-payout-0. (org.apache.kafka.storage.internals.log.LogLoader)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,338] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=claim-payout-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,343] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2026-01-04 16:51:20,345] INFO Completed load of Log(dir=/tmp/kafka-logs/claim-payout-0, topicId=Ceyh8gjaRv6_eQYkpZbVqg, topic=claim-payout, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (57/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,345] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-2, topicId=PgjRFg-WSnmb3Sonhd-W2g, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (58/58 completed in /tmp/kafka-logs) (kafka.log.LogManager)
eureka        | 
eureka        |   .   ____          _            __ _ _
eureka        |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
eureka        | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
eureka        |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
eureka        |   '  |____| .__|_| |_|_| |_\__, | / / / /
eureka        |  =========|_|==============|___/=/_/_/_/
eureka        | 
eureka        |  :: Spring Boot ::                (v4.0.1)
eureka        | 
kafkaQueue    | [2026-01-04 16:51:20,353] INFO Loaded 58 logs in 341ms (unclean log dirs = ArrayBuffer(/tmp/kafka-logs)) (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,354] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,355] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafkaQueue    | [2026-01-04 16:51:20,413] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafkaQueue    | [2026-01-04 16:51:20,413] INFO [AddPartitionsToTxnSenderThread-1]: Starting (org.apache.kafka.server.transaction.AddPartitionsToTxnManager)
kafkaQueue    | [2026-01-04 16:51:20,414] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2026-01-04 16:51:20,414] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2026-01-04 16:51:20,415] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2026-01-04 16:51:20,417] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafkaQueue    | [2026-01-04 16:51:20,417] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2026-01-04 16:51:20,417] INFO [ShareCoordinator id=1] Starting up. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2026-01-04 16:51:20,417] INFO [ShareCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2026-01-04 16:51:20,422] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(claim-payout-0, __consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, policy-renewal-reminder-0, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, claim-submission-email-0, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, otp-email-0, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, claim-decision-email-0, policy-purchase-email-0, account-activation-email-0, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, payout-email-0, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafkaQueue    | [2026-01-04 16:51:20,434] INFO [Partition claim-payout-0 broker=1] Log loaded for partition claim-payout-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,445] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,450] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 9 (kafka.cluster.Partition)
eureka        | 2026-01-04T16:51:20.448Z  INFO 1 --- [Service-Registry] [           main] o.e.s.ServiceRegistryApplication         : Starting ServiceRegistryApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Service-Registry-0.0.1-SNAPSHOT.jar started by root in /app)
eureka        | 2026-01-04T16:51:20.453Z  INFO 1 --- [Service-Registry] [           main] o.e.s.ServiceRegistryApplication         : No active profile set, falling back to 1 default profile: "default"
kafkaQueue    | [2026-01-04 16:51:20,455] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,460] INFO [Partition policy-renewal-reminder-0 broker=1] Log loaded for partition policy-renewal-reminder-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,464] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,468] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,472] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,477] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,481] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,485] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,488] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,492] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,496] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
eureka        | 2026-01-04T16:51:20.499Z  INFO 1 --- [Service-Registry] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
eureka        | 2026-01-04T16:51:20.499Z  INFO 1 --- [Service-Registry] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Service-Registry, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
kafkaQueue    | [2026-01-04 16:51:20,501] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,505] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,509] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,512] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,516] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,520] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,524] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,527] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,531] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,535] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,538] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,542] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,545] INFO [Partition claim-submission-email-0 broker=1] Log loaded for partition claim-submission-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,549] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,553] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,557] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,560] INFO [Partition otp-email-0 broker=1] Log loaded for partition otp-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,564] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,568] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,572] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,577] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,586] INFO [Partition claim-decision-email-0 broker=1] Log loaded for partition claim-decision-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,590] INFO [Partition policy-purchase-email-0 broker=1] Log loaded for partition policy-purchase-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,595] INFO [Partition account-activation-email-0 broker=1] Log loaded for partition account-activation-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,599] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,603] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,607] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,611] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,615] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,619] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,623] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,626] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,630] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,634] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,638] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,642] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,647] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,651] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,655] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,659] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,663] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,667] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,671] INFO [Partition payout-email-0 broker=1] Log loaded for partition payout-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,676] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue    | [2026-01-04 16:51:20,684] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-13 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,686] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-46 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,686] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-9 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,686] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-42 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,687] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-21 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,687] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-17 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,687] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-30 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,687] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-26 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,688] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-5 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,688] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-38 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,688] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-1 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,695] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-34 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,695] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-16 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,695] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-45 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,695] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-12 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,695] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-41 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,696] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-24 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,696] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-20 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,696] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-49 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,696] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-0 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,697] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-29 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,697] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-25 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,697] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-8 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,697] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-37 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,697] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-4 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-9 with epoch 2 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-33 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-42 with epoch 2 in 10ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-13 with epoch 2 in 9ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-15 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-48 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-11 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,698] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-44 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-23 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-19 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-32 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-28 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-7 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,699] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-40 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,700] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-3 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,700] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-36 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,700] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-47 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,700] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-14 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,701] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-43 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,701] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-10 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,701] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-22 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,701] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-18 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-31 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-27 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-39 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-6 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-35 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,702] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-2 with epoch 2 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,704] INFO [DynamicConfigPublisher broker id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2026-01-04 16:51:20,706] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2026-01-04 16:51:20,714] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-38 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,714] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-17 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,714] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Loaded classic group email-service-group with 7 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:20,714] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-12 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,715] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-34 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,715] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-20 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,715] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-49 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-46 with epoch 2 in 27ms where 10ms was spent in the scheduler. Loaded 9 records which total to 2418 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,715] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-0 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,715] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-29 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-21 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-1 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-45 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-23 with epoch 2 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-30 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-48 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-25 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-33 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-15 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,716] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-44 with epoch 2 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-37 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-16 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-11 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-4 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-26 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-41 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-5 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-24 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,717] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-8 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-7 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-32 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-28 with epoch 2 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Loaded classic group billing-service-group with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-3 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-19 with epoch 2 in 19ms where 16ms was spent in the scheduler. Loaded 3 records which total to 656 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-40 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-43 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-36 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-18 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-47 with epoch 2 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-22 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-10 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-6 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-31 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-39 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,719] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-27 with epoch 2 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,720] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-35 with epoch 2 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,720] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-2 with epoch 2 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,720] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-14 with epoch 2 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:20,732] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2026-01-04 16:51:20,741] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 506 (org.apache.kafka.image.loader.MetadataLoader)
eureka        | 2026-01-04T16:51:21.247Z  INFO 1 --- [Service-Registry] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=b546ab9b-bc1c-3439-8253-6390aac21ef1
eureka        | 2026-01-04T16:51:21.455Z  INFO 1 --- [Service-Registry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8761 (http)
eureka        | 2026-01-04T16:51:21.467Z  INFO 1 --- [Service-Registry] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
eureka        | 2026-01-04T16:51:21.467Z  INFO 1 --- [Service-Registry] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
eureka        | 2026-01-04T16:51:21.487Z  INFO 1 --- [Service-Registry] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 985 ms
kafkaQueue    | [2026-01-04 16:51:21,999] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
eureka        | 2026-01-04T16:51:22.294Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka        | 2026-01-04T16:51:22.295Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka        | 2026-01-04T16:51:22.424Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka        | 2026-01-04T16:51:22.425Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka        | 2026-01-04T16:51:22.572Z  INFO 1 --- [Service-Registry] [           main] o.s.v.b.OptionalValidatorFactoryBean     : Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
eureka        | 2026-01-04T16:51:23.205Z  WARN 1 --- [Service-Registry] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
eureka        | 2026-01-04T16:51:23.222Z  INFO 1 --- [Service-Registry] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eureka        | 2026-01-04T16:51:23.234Z  INFO 1 --- [Service-Registry] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
eureka        | 2026-01-04T16:51:23.234Z  INFO 1 --- [Service-Registry] [           main] com.netflix.discovery.DiscoveryClient    : Client configured to neither register nor query for data.
eureka        | 2026-01-04T16:51:23.235Z  INFO 1 --- [Service-Registry] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545483234 with initial instances count: 0
eureka        | 2026-01-04T16:51:23.262Z  INFO 1 --- [Service-Registry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initializing ...
eureka        | 2026-01-04T16:51:23.263Z  INFO 1 --- [Service-Registry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Adding new peer nodes [http://localhost:8761/eureka/]
eureka        | 2026-01-04T16:51:23.348Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka        | 2026-01-04T16:51:23.348Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka        | 2026-01-04T16:51:23.349Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka        | 2026-01-04T16:51:23.349Z  INFO 1 --- [Service-Registry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka        | 2026-01-04T16:51:23.380Z  INFO 1 --- [Service-Registry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Replica node URL:  http://localhost:8761/eureka/
eureka        | 2026-01-04T16:51:23.393Z  INFO 1 --- [Service-Registry] [           main] c.n.e.registry.AbstractInstanceRegistry  : Finished initializing remote region registries. All known remote regions: []
eureka        | 2026-01-04T16:51:23.393Z  INFO 1 --- [Service-Registry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initialized
eureka        | 2026-01-04T16:51:23.401Z  INFO 1 --- [Service-Registry] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
eureka        | 2026-01-04T16:51:23.432Z  INFO 1 --- [Service-Registry] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application SERVICE-REGISTRY with eureka with status UP
eureka        | 2026-01-04T16:51:23.442Z  INFO 1 --- [Service-Registry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : isAws returned false
eureka        | 2026-01-04T16:51:23.443Z  INFO 1 --- [Service-Registry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : Initialized server context
eureka        | 2026-01-04T16:51:23.443Z  INFO 1 --- [Service-Registry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node
eureka        | 2026-01-04T16:51:23.443Z  INFO 1 --- [Service-Registry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1
eureka        | 2026-01-04T16:51:23.443Z  INFO 1 --- [Service-Registry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP
eureka        | 2026-01-04T16:51:23.444Z  INFO 1 --- [Service-Registry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8761 (http) with context path '/'
eureka        | 2026-01-04T16:51:23.445Z  INFO 1 --- [Service-Registry] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8761
eureka        | 2026-01-04T16:51:23.446Z  INFO 1 --- [Service-Registry] [       Thread-9] e.s.EurekaServerInitializerConfiguration : Started Eureka Server
eureka        | 2026-01-04T16:51:23.456Z  INFO 1 --- [Service-Registry] [           main] o.e.s.ServiceRegistryApplication         : Started ServiceRegistryApplication in 5.746 seconds (process running for 6.938)
kafkaQueue    | [2026-01-04 16:51:24,001] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:26,003] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
eureka        | 2026-01-04T16:51:26.636Z  INFO 1 --- [Service-Registry] [nio-8761-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
eureka        | 2026-01-04T16:51:26.636Z  INFO 1 --- [Service-Registry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
eureka        | 2026-01-04T16:51:26.637Z  INFO 1 --- [Service-Registry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
kafkaQueue    | [2026-01-04 16:51:28,025] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:29,055] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, claim-payout-0, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, policy-renewal-reminder-0, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, claim-submission-email-0, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, otp-email-0, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, claim-decision-email-0, policy-purchase-email-0, account-activation-email-0, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, payout-email-0, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafkaQueue    | [2026-01-04 16:51:29,083] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-13 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-46 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-9 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-42 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-21 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-17 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,086] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-30 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,087] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-26 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,087] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-5 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,087] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-38 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,088] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-46 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,089] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-9 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,089] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-26 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,089] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-21 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,090] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-26 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,092] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-21 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,092] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-42 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,092] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] [GroupId=email-service-group] Unloading group metadata for generation 1. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-46 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,091] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-1 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-34 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-16 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-45 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-12 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-41 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-24 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-20 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-49 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-0 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-29 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-25 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-8 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-37 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-4 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-33 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-15 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-48 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-11 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-44 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-23 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-19 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-32 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-28 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-7 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-40 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-3 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-36 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-47 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-14 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-43 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,095] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-10 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,091] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-9 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-19 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] [GroupId=billing-service-group] Unloading group metadata for generation 1. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-19 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-20 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-20 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-16 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-16 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-7 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,096] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-7 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,097] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-13 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,097] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-13 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,097] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-12 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,094] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-42 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,098] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-36 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,098] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-44 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,093] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-5 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-5 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-43 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-36 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-17 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-17 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,100] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-29 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,100] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-29 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,100] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-40 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,098] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-12 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,100] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-45 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,097] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-22 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,101] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-18 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,100] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-43 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,101] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-3 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,102] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-31 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,102] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-27 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,102] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-39 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,099] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-44 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,102] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-31 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-31 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-10 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-10 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-23 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,102] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-3 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-23 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-4 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-8 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-4 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,101] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-45 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,101] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-40 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-48 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-8 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,103] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-6 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,105] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-14 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,105] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-48 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,105] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-41 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-34 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,106] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-41 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,104] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-18 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,106] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-18 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,106] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-34 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,106] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-14 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,105] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-35 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,106] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-1 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-1 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-2 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-35 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-47 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,109] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-47 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-15 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,110] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-15 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,109] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-35 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,107] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-0 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,110] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-25 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,111] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-33 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,111] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-33 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,111] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-0 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,111] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-30 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,111] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-38 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-38 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-24 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-24 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-37 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-25 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-2 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-6 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-37 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,112] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-30 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-2 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-32 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-6 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-39 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-32 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-28 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,113] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-27 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-11 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-39 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-22 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-27 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,114] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-28 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,115] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-11 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,115] INFO [GroupCoordinator id=1] Started unloading metadata for __consumer_offsets-49 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,115] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-22 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:29,116] INFO [GroupCoordinator id=1] Finished unloading metadata for __consumer_offsets-49 with epoch OptionalInt[3]. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,108] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 586 (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:30,199] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-13 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,199] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-46 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,199] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-9 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-42 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-21 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-13 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-21 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-42 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-17 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,200] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-9 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-46 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-17 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-30 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-30 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-26 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-26 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-5 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-38 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-1 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,201] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-34 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-16 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-1 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-34 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-5 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-38 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-45 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-12 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-41 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-24 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-20 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-49 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-0 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-29 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-25 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-8 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-37 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-4 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-33 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-15 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-48 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-11 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-44 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-23 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-19 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-32 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-28 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,202] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-25 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-15 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-4 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-41 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-33 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-24 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-7 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-40 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-20 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-32 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-8 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-11 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-16 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-7 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-12 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-44 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-3 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-45 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,203] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-48 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-19 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-40 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-0 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-23 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-36 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-47 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-14 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-3 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-43 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-10 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-22 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-14 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-18 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,204] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-10 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-37 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-49 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-31 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-18 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,206] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-29 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-28 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,206] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-22 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,206] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-43 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,206] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-31 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,207] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-36 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-27 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,207] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-39 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,205] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-47 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,207] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-27 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,208] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-6 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,208] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-39 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,208] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-35 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,208] INFO [GroupCoordinator id=1] Scheduling unloading of metadata for __consumer_offsets-2 with epoch OptionalInt[3] (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,209] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-35 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,209] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-6 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,209] INFO [GroupCoordinator id=1] Ignored unloading metadata for __consumer_offsets-2 in epoch OptionalInt[3] since metadata was never loaded. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,231] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:30,235] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,236] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,236] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,240] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2026-01-04 16:51:30,254] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:30,256] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,405] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(claim-payout-0, __consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, policy-renewal-reminder-0, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, claim-submission-email-0, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, otp-email-0, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, claim-decision-email-0, policy-purchase-email-0, account-activation-email-0, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, payout-email-0, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafkaQueue    | [2026-01-04 16:51:30,411] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2026-01-04 16:51:30,415] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,418] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2026-01-04 16:51:30,420] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2026-01-04 16:51:30,423] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2026-01-04 16:51:30,426] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,428] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,430] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,430] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,430] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafkaQueue    | [2026-01-04 16:51:30,431] INFO Kafka version: 4.1.1 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2026-01-04 16:51:30,432] INFO Kafka commitId: be816b82d25370ce (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2026-01-04 16:51:30,432] INFO Kafka startTimeMs: 1767545490431 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2026-01-04 16:51:30,437] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
kafkaQueue    | [2026-01-04 16:51:30,815] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-13 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,816] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-46 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-9 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-42 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-21 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-17 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-30 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,817] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-26 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,820] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-5 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,820] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-13 with epoch 4 in 1ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,825] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-38 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,828] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-1 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,829] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Loaded classic group email-service-group with 7 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:30,829] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-30 with epoch 4 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,829] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-9 with epoch 4 in 10ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,830] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-46 with epoch 4 in 9ms where 1ms was spent in the scheduler. Loaded 9 records which total to 2418 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,830] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-21 with epoch 4 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,830] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-38 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,830] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-34 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,831] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-5 with epoch 4 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,831] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-42 with epoch 4 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,832] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-17 with epoch 4 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,832] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-26 with epoch 4 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,833] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-1 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,834] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-16 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,835] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-34 with epoch 4 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,836] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-45 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,836] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-16 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,836] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-12 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,838] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-41 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,838] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-24 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,839] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-20 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,841] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-49 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,841] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-0 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,842] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-29 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,842] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-25 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,839] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-45 with epoch 4 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,847] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-29 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,847] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-41 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,848] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-12 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,848] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-49 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,848] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-20 with epoch 4 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,850] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-24 with epoch 4 in 6ms where 6ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,851] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-0 with epoch 4 in 3ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,851] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-8 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,854] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-37 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,855] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-8 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,855] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-4 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,858] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-25 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,858] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-33 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,859] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-15 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,859] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-37 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,860] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-33 with epoch 4 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,860] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-48 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,861] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-15 with epoch 4 in 1ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,860] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-4 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,865] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-11 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,866] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-44 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,867] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-23 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,867] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-19 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,867] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-32 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,868] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-28 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,869] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-7 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,870] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-40 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,872] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-3 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,873] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-48 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,874] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-36 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,876] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-47 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,877] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-14 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,878] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-44 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,881] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-43 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,881] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-11 with epoch 4 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,881] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-7 with epoch 4 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,878] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-40 with epoch 4 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,882] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-28 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,883] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-23 with epoch 4 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,881] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-10 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,893] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-32 with epoch 4 in 23ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,894] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-36 with epoch 4 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,893] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-22 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,897] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-14 with epoch 4 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,898] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-43 with epoch 4 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,897] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-3 with epoch 4 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,898] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-47 with epoch 4 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,906] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-18 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,907] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-31 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,908] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-22 with epoch 4 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,908] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-10 with epoch 4 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,909] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-27 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,907] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Loaded classic group billing-service-group with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue    | [2026-01-04 16:51:30,910] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-39 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,910] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-6 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,910] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-19 with epoch 4 in 20ms where 12ms was spent in the scheduler. Loaded 3 records which total to 656 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,910] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-35 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,910] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-2 with epoch 4 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,912] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-18 with epoch 4 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,913] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-39 with epoch 4 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,913] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-35 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,913] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-31 with epoch 4 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,914] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-6 with epoch 4 in 3ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,914] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-2 with epoch 4 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue    | [2026-01-04 16:51:30,916] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-27 with epoch 4 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
configserver  | 2026-01-04T16:51:32.157Z  INFO 1 --- [Config-Server] [nio-8888-exec-5] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Policy-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:32.912Z  INFO 1 --- [Config-Server] [io-8888-exec-10] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Billing-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:33.649Z  INFO 1 --- [Config-Server] [nio-8888-exec-9] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Claims-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:34.391Z  INFO 1 --- [Config-Server] [nio-8888-exec-8] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Identity-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:35.111Z  INFO 1 --- [Config-Server] [nio-8888-exec-7] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Provider-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:35.889Z  INFO 1 --- [Config-Server] [nio-8888-exec-6] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Email-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:36.624Z  INFO 1 --- [Config-Server] [io-8888-exec-10] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Provider-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver  | 2026-01-04T16:51:36.624Z  INFO 1 --- [Config-Server] [io-8888-exec-10] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Provider-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
providerservice  | 
providerservice  |   .   ____          _            __ _ _
providerservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
providerservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
providerservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
providerservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
providerservice  |  =========|_|==============|___/=/_/_/_/
providerservice  | 
providerservice  |  :: Spring Boot ::                (v4.0.1)
providerservice  | 
providerservice  | 2026-01-04T16:51:36.739Z  INFO 1 --- [Provider-Service] [           main] o.e.p.ProviderServiceApplication         : Starting ProviderServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Provider-Service-0.0.1-SNAPSHOT.jar started by root in /app)
providerservice  | 2026-01-04T16:51:36.742Z  INFO 1 --- [Provider-Service] [           main] o.e.p.ProviderServiceApplication         : The following 1 profile is active: "docker"
providerservice  | 2026-01-04T16:51:36.785Z  INFO 1 --- [Provider-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
providerservice  | 2026-01-04T16:51:36.786Z  INFO 1 --- [Provider-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Provider-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
providerservice  | 2026-01-04T16:51:36.786Z  INFO 1 --- [Provider-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
providerservice  | 2026-01-04T16:51:36.786Z  INFO 1 --- [Provider-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Provider-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
providerservice  | 2026-01-04T16:51:37.343Z  INFO 1 --- [Provider-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
configserver     | 2026-01-04T16:51:37.379Z  INFO 1 --- [Config-Server] [nio-8888-exec-5] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Identity-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver     | 2026-01-04T16:51:37.379Z  INFO 1 --- [Config-Server] [nio-8888-exec-5] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Identity-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
identityservice  | 
identityservice  |   .   ____          _            __ _ _
identityservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
identityservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
identityservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
identityservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
identityservice  |  =========|_|==============|___/=/_/_/_/
identityservice  | 
identityservice  |  :: Spring Boot ::                (v4.0.1)
identityservice  | 
identityservice  | 2026-01-04T16:51:37.510Z  INFO 1 --- [Identity-Service] [           main] o.e.i.IdentityServiceApplication         : Starting IdentityServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Identity-Service-0.0.1-SNAPSHOT.jar started by root in /app)
identityservice  | 2026-01-04T16:51:37.513Z  INFO 1 --- [Identity-Service] [           main] o.e.i.IdentityServiceApplication         : The following 1 profile is active: "docker"
providerservice  | 2026-01-04T16:51:37.515Z  INFO 1 --- [Provider-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 165 ms. Found 4 JPA repository interfaces.
identityservice  | 2026-01-04T16:51:37.567Z  INFO 1 --- [Identity-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
identityservice  | 2026-01-04T16:51:37.568Z  INFO 1 --- [Identity-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Identity-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
identityservice  | 2026-01-04T16:51:37.570Z  INFO 1 --- [Identity-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
identityservice  | 2026-01-04T16:51:37.570Z  INFO 1 --- [Identity-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Identity-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
configserver     | 2026-01-04T16:51:38.174Z  INFO 1 --- [Config-Server] [nio-8888-exec-4] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Claims-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver     | 2026-01-04T16:51:38.175Z  INFO 1 --- [Config-Server] [nio-8888-exec-4] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Claims-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
providerservice  | 2026-01-04T16:51:38.187Z  INFO 1 --- [Provider-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=b85936ef-c0b9-35de-9051-448457dd4476
claimsservice    | 
claimsservice    |   .   ____          _            __ _ _
claimsservice    |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
claimsservice    | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
claimsservice    |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
claimsservice    |   '  |____| .__|_| |_|_| |_\__, | / / / /
claimsservice    |  =========|_|==============|___/=/_/_/_/
claimsservice    | 
claimsservice    |  :: Spring Boot ::                (v4.0.1)
claimsservice    | 
configserver     | 2026-01-04T16:51:39.063Z  INFO 1 --- [Config-Server] [nio-8888-exec-3] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Billing-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver     | 2026-01-04T16:51:39.064Z  INFO 1 --- [Config-Server] [nio-8888-exec-3] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Billing-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
claimsservice    | 2026-01-04T16:51:39.061Z  INFO 1 --- [Claims-Service] [           main] o.e.c.ClaimsServiceApplication           : Starting ClaimsServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Claims-Service-0.0.1-SNAPSHOT.jar started by root in /app)
claimsservice    | 2026-01-04T16:51:39.078Z  INFO 1 --- [Claims-Service] [           main] o.e.c.ClaimsServiceApplication           : The following 1 profile is active: "docker"
claimsservice    | 2026-01-04T16:51:39.372Z  INFO 1 --- [Claims-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
claimsservice    | 2026-01-04T16:51:39.373Z  INFO 1 --- [Claims-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Claims-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
claimsservice    | 2026-01-04T16:51:39.377Z  INFO 1 --- [Claims-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
claimsservice    | 2026-01-04T16:51:39.377Z  INFO 1 --- [Claims-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Claims-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
billingservice   | 
billingservice   |   .   ____          _            __ _ _
billingservice   |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
billingservice   | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
billingservice   |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
billingservice   |   '  |____| .__|_| |_|_| |_\__, | / / / /
billingservice   |  =========|_|==============|___/=/_/_/_/
billingservice   | 
billingservice   |  :: Spring Boot ::                (v4.0.1)
billingservice   | 
configserver     | 2026-01-04T16:51:39.955Z  INFO 1 --- [Config-Server] [nio-8888-exec-2] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Policy-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver     | 2026-01-04T16:51:39.956Z  INFO 1 --- [Config-Server] [nio-8888-exec-2] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Policy-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
providerservice  | 2026-01-04T16:51:40.046Z  INFO 1 --- [Provider-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8082 (http)
billingservice   | 2026-01-04T16:51:40.040Z  INFO 1 --- [Billing-Service] [           main] o.e.b.BillingServiceApplication          : Starting BillingServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Billing-Service-0.0.1-SNAPSHOT.jar started by root in /app)
billingservice   | 2026-01-04T16:51:40.071Z  INFO 1 --- [Billing-Service] [           main] o.e.b.BillingServiceApplication          : The following 1 profile is active: "docker"
providerservice  | 2026-01-04T16:51:40.146Z  INFO 1 --- [Provider-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
providerservice  | 2026-01-04T16:51:40.147Z  INFO 1 --- [Provider-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
providerservice  | 2026-01-04T16:51:40.247Z  INFO 1 --- [Provider-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 3455 ms
billingservice   | 2026-01-04T16:51:40.362Z  INFO 1 --- [Billing-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
billingservice   | 2026-01-04T16:51:40.363Z  INFO 1 --- [Billing-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Billing-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
billingservice   | 2026-01-04T16:51:40.366Z  INFO 1 --- [Billing-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
billingservice   | 2026-01-04T16:51:40.367Z  INFO 1 --- [Billing-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Billing-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
policyservice    | 
policyservice    |   .   ____          _            __ _ _
policyservice    |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
policyservice    | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
policyservice    |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
policyservice    |   '  |____| .__|_| |_|_| |_\__, | / / / /
policyservice    |  =========|_|==============|___/=/_/_/_/
policyservice    | 
policyservice    |  :: Spring Boot ::                (v4.0.1)
policyservice    | 
configserver     | 2026-01-04T16:51:40.998Z  INFO 1 --- [Config-Server] [nio-8888-exec-1] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Api-Gateway.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
policyservice    | 2026-01-04T16:51:41.242Z  INFO 1 --- [Policy-Service] [           main] o.e.p.PolicyServiceApplication           : Starting PolicyServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/Policy-Service-0.0.1-SNAPSHOT.jar started by root in /app)
policyservice    | 2026-01-04T16:51:41.295Z  INFO 1 --- [Policy-Service] [           main] o.e.p.PolicyServiceApplication           : The following 1 profile is active: "docker"
identityservice  | 2026-01-04T16:51:41.328Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
identityservice  | 2026-01-04T16:51:41.332Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
providerservice  | 2026-01-04T16:51:41.427Z  INFO 1 --- [Provider-Service] [           main] org.hibernate.orm.jpa                    : HHH008540: Processing PersistenceUnitInfo [name: default]
policyservice    | 2026-01-04T16:51:41.579Z  INFO 1 --- [Policy-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
policyservice    | 2026-01-04T16:51:41.580Z  INFO 1 --- [Policy-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Policy-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
policyservice    | 2026-01-04T16:51:41.588Z  INFO 1 --- [Policy-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
policyservice    | 2026-01-04T16:51:41.590Z  INFO 1 --- [Policy-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Policy-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
providerservice  | 2026-01-04T16:51:41.689Z  INFO 1 --- [Provider-Service] [           main] org.hibernate.orm.core                   : HHH000001: Hibernate ORM core version 7.2.0.Final
identityservice  | 2026-01-04T16:51:41.884Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 516 ms. Found 1 MongoDB repository interface.
apigateway       | 
apigateway       |   .   ____          _            __ _ _
apigateway       |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
apigateway       | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
apigateway       |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
apigateway       |   '  |____| .__|_| |_|_| |_\__, | / / / /
apigateway       |  =========|_|==============|___/=/_/_/_/
apigateway       | 
apigateway       |  :: Spring Boot ::                (v3.4.0)
apigateway       | 
identityservice  | 2026-01-04T16:51:41.967Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
identityservice  | 2026-01-04T16:51:41.973Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
identityservice  | 2026-01-04T16:51:42.054Z  INFO 1 --- [Identity-Service] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.identityservice.repository.UsersRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
identityservice  | 2026-01-04T16:51:42.055Z  INFO 1 --- [Identity-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 22 ms. Found 0 Redis repository interfaces.
apigateway       | 2026-01-04T16:51:42.523Z  INFO 1 --- [Api-Gateway] [           main] o.e.apigateway.ApiGatewayApplication     : Starting ApiGatewayApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ApiGateway-0.0.1-SNAPSHOT.jar started by root in /app)
apigateway       | 2026-01-04T16:51:42.541Z  INFO 1 --- [Api-Gateway] [           main] o.e.apigateway.ApiGatewayApplication     : No active profile set, falling back to 1 default profile: "default"
configserver     | 2026-01-04T16:51:42.828Z  INFO 1 --- [Config-Server] [nio-8888-exec-9] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Email-Service-docker.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
configserver     | 2026-01-04T16:51:42.829Z  INFO 1 --- [Config-Server] [nio-8888-exec-9] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-10072431985512339274/Email-Service.properties]' via location 'file:/tmp/config-repo-10072431985512339274/'
apigateway       | 2026-01-04T16:51:42.933Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
apigateway       | 2026-01-04T16:51:42.934Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Api-Gateway, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
emailservice     | 
emailservice     |   .   ____          _            __ _ _
emailservice     |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
emailservice     | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
emailservice     |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
emailservice     |   '  |____| .__|_| |_|_| |_\__, | / / / /
emailservice     |  =========|_|==============|___/=/_/_/_/
emailservice     | 
emailservice     |  :: Spring Boot ::                (v4.0.1)
emailservice     | 
identityservice  | 2026-01-04T16:51:44.072Z  INFO 1 --- [Identity-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=e760a6cd-7e9e-35b7-a4fd-0b13ee85e910
emailservice     | 2026-01-04T16:51:44.062Z  INFO 1 --- [Email-Service] [           main] o.e.e.EmailServiceApplication            : Starting EmailServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/EmailService-0.0.1-SNAPSHOT.jar started by root in /app)
emailservice     | 2026-01-04T16:51:44.081Z  INFO 1 --- [Email-Service] [           main] o.e.e.EmailServiceApplication            : The following 1 profile is active: "docker"
emailservice     | 2026-01-04T16:51:44.313Z  INFO 1 --- [Email-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
emailservice     | 2026-01-04T16:51:44.314Z  INFO 1 --- [Email-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Email-Service, profiles=[default], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
emailservice     | 2026-01-04T16:51:44.322Z  INFO 1 --- [Email-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
emailservice     | 2026-01-04T16:51:44.323Z  INFO 1 --- [Email-Service] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=Email-Service, profiles=[docker], label=null, version=e1b217d56af0f5ca0f839aad7ff496a030e7983f, state=
providerservice  | 2026-01-04T16:51:44.562Z  INFO 1 --- [Provider-Service] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
claimsservice    | 2026-01-04T16:51:44.572Z  INFO 1 --- [Claims-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
providerservice  | 2026-01-04T16:51:44.677Z  INFO 1 --- [Provider-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
billingservice   | 2026-01-04T16:51:45.079Z  INFO 1 --- [Billing-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
claimsservice    | 2026-01-04T16:51:45.284Z  INFO 1 --- [Claims-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 643 ms. Found 2 JPA repository interfaces.
providerservice  | 2026-01-04T16:51:45.533Z  INFO 1 --- [Provider-Service] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@457b8fc3
providerservice  | 2026-01-04T16:51:45.542Z  INFO 1 --- [Provider-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
providerservice  | 2026-01-04T16:51:45.992Z  INFO 1 --- [Provider-Service] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
providerservice  | 	Database JDBC URL [jdbc:mysql://sqldb:3306/ProviderDB?createDatabaseIfNotExist=true&allowPublicKeyRetrieval=true&useSSL=false]
providerservice  | 	Database driver: MySQL Connector/J
providerservice  | 	Database dialect: MySQLDialect
providerservice  | 	Database version: 9.5
providerservice  | 	Default catalog/schema: ProviderDB/undefined
providerservice  | 	Autocommit mode: undefined/unknown
providerservice  | 	Isolation level: REPEATABLE_READ [default REPEATABLE_READ]
providerservice  | 	JDBC fetch size: none
providerservice  | 	Pool: DataSourceConnectionProvider
providerservice  | 	Minimum pool size: undefined/unknown
providerservice  | 	Maximum pool size: undefined/unknown
billingservice   | 2026-01-04T16:51:46.075Z  INFO 1 --- [Billing-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 946 ms. Found 3 MongoDB repository interfaces.
identityservice  | 2026-01-04T16:51:46.098Z  INFO 1 --- [Identity-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8080 (http)
identityservice  | 2026-01-04T16:51:46.133Z  INFO 1 --- [Identity-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
identityservice  | 2026-01-04T16:51:46.138Z  INFO 1 --- [Identity-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
policyservice    | 2026-01-04T16:51:46.209Z  INFO 1 --- [Policy-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
identityservice  | 2026-01-04T16:51:46.303Z  INFO 1 --- [Identity-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 8726 ms
policyservice    | 2026-01-04T16:51:46.966Z  INFO 1 --- [Policy-Service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 709 ms. Found 2 JPA repository interfaces.
mongo            | {"t":{"$date":"2026-01-04T16:51:47.206+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.21.0.12:35064","isLoadBalanced":false,"uuid":{"uuid":{"$uuid":"e2ccbc9a-b01d-4ee3-9d35-101ad6af000c"}},"connectionId":1,"connectionCount":1}}
identityservice  | 2026-01-04T16:51:47.259Z  INFO 1 --- [Identity-Service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|spring-boot|sync", "version": "5.6.2"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.17.12-300.fc43.x86_64"}, "platform": "Java/Eclipse Adoptium/21.0.9+10-LTS", "env": {"container": {"runtime": "docker"}}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4f7bb8df, com.mongodb.Jep395RecordCodecProvider@269c7104, com.mongodb.KotlinCodecProvider@6de84336, EnumCodecProvider{}]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongo:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
mongo            | {"t":{"$date":"2026-01-04T16:51:47.284+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn1","msg":"client metadata","attr":{"remote":"172.21.0.12:35064","client":"conn1","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
mongo            | {"t":{"$date":"2026-01-04T16:51:47.284+00:00"},"s":"I",  "c":"ACCESS",   "id":10483900,"ctx":"conn1","msg":"Connection not authenticating","attr":{"client":"172.21.0.12:35064","doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
identityservice  | 2026-01-04T16:51:47.359Z  INFO 1 --- [Identity-Service] [l'}-mongo:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongo:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=27, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=144247107, minRoundTripTimeNanos=0}
mongo            | {"t":{"$date":"2026-01-04T16:51:47.365+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.21.0.12:35074","isLoadBalanced":false,"uuid":{"uuid":{"$uuid":"3ec82edb-ac1c-400f-98c3-b5d8067c97de"}},"connectionId":2,"connectionCount":2}}
mongo            | {"t":{"$date":"2026-01-04T16:51:47.374+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn2","msg":"client metadata","attr":{"remote":"172.21.0.12:35074","client":"conn2","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
mongo            | {"t":{"$date":"2026-01-04T16:51:47.374+00:00"},"s":"I",  "c":"ACCESS",   "id":10483900,"ctx":"conn2","msg":"Connection not authenticating","attr":{"client":"172.21.0.12:35074","doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
claimsservice    | 2026-01-04T16:51:47.396Z  INFO 1 --- [Claims-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=9f303d98-5872-3e55-bc23-e2536898996c
billingservice   | 2026-01-04T16:51:48.375Z  INFO 1 --- [Billing-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=1a52ab1f-1700-3c47-b56f-5f227d3c41d4
emailservice     | 2026-01-04T16:51:48.730Z  INFO 1 --- [Email-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=7da7a4bd-f51d-3fdc-906e-a55da09e73f6
apigateway       | 2026-01-04T16:51:48.964Z  INFO 1 --- [Api-Gateway] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=f3f2424c-8de8-3273-b0fb-8226e559bab7
policyservice    | 2026-01-04T16:51:49.051Z  INFO 1 --- [Policy-Service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=1bbc00b9-43d6-3753-8542-7828fc78fe20
billingservice   | 2026-01-04T16:51:50.890Z  INFO 1 --- [Billing-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8084 (http)
billingservice   | 2026-01-04T16:51:50.994Z  INFO 1 --- [Billing-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
billingservice   | 2026-01-04T16:51:50.997Z  INFO 1 --- [Billing-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
billingservice   | 2026-01-04T16:51:51.224Z  INFO 1 --- [Billing-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 10831 ms
claimsservice    | 2026-01-04T16:51:51.236Z  INFO 1 --- [Claims-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8083 (http)
claimsservice    | 2026-01-04T16:51:51.299Z  INFO 1 --- [Claims-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
claimsservice    | 2026-01-04T16:51:51.302Z  INFO 1 --- [Claims-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
providerservice  | 2026-01-04T16:51:51.331Z  INFO 1 --- [Provider-Service] [           main] org.hibernate.orm.core                   : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
claimsservice    | 2026-01-04T16:51:51.474Z  INFO 1 --- [Claims-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 12085 ms
identityservice  | 2026-01-04T16:51:51.535Z  INFO 1 --- [Identity-Service] [           main] eAuthenticationProviderManagerConfigurer : Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
identityservice  | 2026-01-04T16:51:51.539Z  WARN 1 --- [Identity-Service] [           main] r$InitializeUserDetailsManagerConfigurer : Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
emailservice     | 2026-01-04T16:51:51.629Z  INFO 1 --- [Email-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8085 (http)
emailservice     | 2026-01-04T16:51:51.721Z  INFO 1 --- [Email-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
emailservice     | 2026-01-04T16:51:51.723Z  INFO 1 --- [Email-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
providerservice  | 2026-01-04T16:51:51.856Z  INFO 1 --- [Provider-Service] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
emailservice     | 2026-01-04T16:51:51.921Z  INFO 1 --- [Email-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 7577 ms
providerservice  | 2026-01-04T16:51:52.471Z  INFO 1 --- [Provider-Service] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
claimsservice    | 2026-01-04T16:51:52.922Z  INFO 1 --- [Claims-Service] [           main] org.hibernate.orm.jpa                    : HHH008540: Processing PersistenceUnitInfo [name: default]
claimsservice    | 2026-01-04T16:51:53.424Z  INFO 1 --- [Claims-Service] [           main] org.hibernate.orm.core                   : HHH000001: Hibernate ORM core version 7.2.0.Final
billingservice   | 2026-01-04T16:51:53.573Z  INFO 1 --- [Billing-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Policy-Service' URL not provided. Will try picking an instance via load-balancing.
providerservice  | 2026-01-04T16:51:54.039Z  WARN 1 --- [Provider-Service] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
policyservice    | 2026-01-04T16:51:54.206Z  INFO 1 --- [Policy-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8081 (http)
policyservice    | 2026-01-04T16:51:54.304Z  INFO 1 --- [Policy-Service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
policyservice    | 2026-01-04T16:51:54.308Z  INFO 1 --- [Policy-Service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.15]
billingservice   | 2026-01-04T16:51:54.456Z  INFO 1 --- [Billing-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Provider-Service' URL not provided. Will try picking an instance via load-balancing.
policyservice    | 2026-01-04T16:51:54.464Z  INFO 1 --- [Policy-Service] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 12849 ms
mongo            | {"t":{"$date":"2026-01-04T16:51:55.619+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.21.0.11:58008","isLoadBalanced":false,"uuid":{"uuid":{"$uuid":"1dff4f97-2e1b-4706-9d02-3e18a5e90f9f"}},"connectionId":3,"connectionCount":3}}
mongo            | {"t":{"$date":"2026-01-04T16:51:55.726+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn3","msg":"client metadata","attr":{"remote":"172.21.0.11:58008","client":"conn3","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
mongo            | {"t":{"$date":"2026-01-04T16:51:55.726+00:00"},"s":"I",  "c":"ACCESS",   "id":10483900,"ctx":"conn3","msg":"Connection not authenticating","attr":{"client":"172.21.0.11:58008","doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
billingservice   | 2026-01-04T16:51:55.720Z  INFO 1 --- [Billing-Service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|spring-boot|sync", "version": "5.6.2"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.17.12-300.fc43.x86_64"}, "platform": "Java/Eclipse Adoptium/21.0.9+10-LTS", "env": {"container": {"runtime": "docker"}}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@284c4f02, com.mongodb.Jep395RecordCodecProvider@709d6de5, com.mongodb.KotlinCodecProvider@1a43a88e, EnumCodecProvider{}]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongo:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
billingservice   | 2026-01-04T16:51:55.874Z  INFO 1 --- [Billing-Service] [l'}-mongo:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongo:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=27, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=221108550, minRoundTripTimeNanos=0}
mongo            | {"t":{"$date":"2026-01-04T16:51:55.880+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.21.0.11:45654","isLoadBalanced":false,"uuid":{"uuid":{"$uuid":"c167ff08-76f1-42d5-8dcf-83bf2842405a"}},"connectionId":4,"connectionCount":4}}
mongo            | {"t":{"$date":"2026-01-04T16:51:55.885+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn4","msg":"client metadata","attr":{"remote":"172.21.0.11:45654","client":"conn4","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
mongo            | {"t":{"$date":"2026-01-04T16:51:55.885+00:00"},"s":"I",  "c":"ACCESS",   "id":10483900,"ctx":"conn4","msg":"Connection not authenticating","attr":{"client":"172.21.0.11:45654","doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
policyservice    | 2026-01-04T16:51:56.030Z  INFO 1 --- [Policy-Service] [           main] org.hibernate.orm.jpa                    : HHH008540: Processing PersistenceUnitInfo [name: default]
policyservice    | 2026-01-04T16:51:56.501Z  INFO 1 --- [Policy-Service] [           main] org.hibernate.orm.core                   : HHH000001: Hibernate ORM core version 7.2.0.Final
emailservice     | 2026-01-04T16:51:56.528Z  INFO 1 --- [Email-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'identity-service' URL not provided. Will try picking an instance via load-balancing.
claimsservice    | 2026-01-04T16:51:56.884Z  INFO 1 --- [Claims-Service] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
claimsservice    | 2026-01-04T16:51:57.133Z  INFO 1 --- [Claims-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
billingservice   | 2026-01-04T16:51:57.394Z  INFO 1 --- [Billing-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Claims-Service' URL not provided. Will try picking an instance via load-balancing.
apigateway       | 2026-01-04T16:51:57.557Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [After]
apigateway       | 2026-01-04T16:51:57.560Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Before]
apigateway       | 2026-01-04T16:51:57.562Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Between]
apigateway       | 2026-01-04T16:51:57.564Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Cookie]
apigateway       | 2026-01-04T16:51:57.568Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Header]
apigateway       | 2026-01-04T16:51:57.569Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Host]
apigateway       | 2026-01-04T16:51:57.574Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Method]
apigateway       | 2026-01-04T16:51:57.575Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Path]
apigateway       | 2026-01-04T16:51:57.578Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Query]
apigateway       | 2026-01-04T16:51:57.580Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [ReadBody]
apigateway       | 2026-01-04T16:51:57.583Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [RemoteAddr]
apigateway       | 2026-01-04T16:51:57.585Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [XForwardedRemoteAddr]
apigateway       | 2026-01-04T16:51:57.588Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Weight]
apigateway       | 2026-01-04T16:51:57.593Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [CloudFoundryRouteService]
providerservice  | 2026-01-04T16:51:57.654Z  INFO 1 --- [Provider-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
providerservice  | 2026-01-04T16:51:57.854Z  WARN 1 --- [Provider-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
providerservice  | 2026-01-04T16:51:57.968Z  INFO 1 --- [Provider-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
claimsservice    | 2026-01-04T16:51:58.169Z  INFO 1 --- [Claims-Service] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@4fe9a396
claimsservice    | 2026-01-04T16:51:58.198Z  INFO 1 --- [Claims-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
providerservice  | 2026-01-04T16:51:58.283Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
providerservice  | 2026-01-04T16:51:58.308Z  INFO 1 --- [Provider-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
providerservice  | 2026-01-04T16:51:58.378Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
providerservice  | 2026-01-04T16:51:58.378Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
providerservice  | 2026-01-04T16:51:58.379Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
providerservice  | 2026-01-04T16:51:58.380Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
providerservice  | 2026-01-04T16:51:58.381Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
providerservice  | 2026-01-04T16:51:58.381Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
providerservice  | 2026-01-04T16:51:58.381Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
claimsservice    | 2026-01-04T16:51:58.677Z  INFO 1 --- [Claims-Service] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
claimsservice    | 	Database JDBC URL [jdbc:mysql://sqldb:3306/ClaimsDB?createDatabaseIfNotExist=true&allowPublicKeyRetrieval=true&useSSL=false]
claimsservice    | 	Database driver: MySQL Connector/J
claimsservice    | 	Database dialect: MySQLDialect
claimsservice    | 	Database version: 9.5
claimsservice    | 	Default catalog/schema: ClaimsDB/undefined
claimsservice    | 	Autocommit mode: undefined/unknown
claimsservice    | 	Isolation level: REPEATABLE_READ [default REPEATABLE_READ]
claimsservice    | 	JDBC fetch size: none
claimsservice    | 	Pool: DataSourceConnectionProvider
claimsservice    | 	Minimum pool size: undefined/unknown
claimsservice    | 	Maximum pool size: undefined/unknown
policyservice    | 2026-01-04T16:51:59.081Z  INFO 1 --- [Policy-Service] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
policyservice    | 2026-01-04T16:51:59.247Z  INFO 1 --- [Policy-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
apigateway       | 2026-01-04T16:51:59.916Z  INFO 1 --- [Api-Gateway] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
policyservice    | 2026-01-04T16:52:00.126Z  INFO 1 --- [Policy-Service] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@1fa796a4
policyservice    | 2026-01-04T16:52:00.141Z  INFO 1 --- [Policy-Service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
apigateway       | 2026-01-04T16:52:00.232Z  WARN 1 --- [Api-Gateway] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
apigateway       | 2026-01-04T16:52:00.443Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
providerservice  | 2026-01-04T16:52:00.457Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
providerservice  | 2026-01-04T16:52:00.468Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
identityservice  | 2026-01-04T16:52:00.463Z  INFO 1 --- [Identity-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
providerservice  | 2026-01-04T16:52:00.482Z  INFO 1 --- [Provider-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
providerservice  | 2026-01-04T16:52:00.515Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545520511 with initial instances count: 0
providerservice  | 2026-01-04T16:52:00.538Z  INFO 1 --- [Provider-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application PROVIDER-SERVICE with eureka with status UP
providerservice  | 2026-01-04T16:52:00.542Z  INFO 1 --- [Provider-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545520542, current=UP, previous=STARTING]
providerservice  | 2026-01-04T16:52:00.563Z  INFO 1 --- [Provider-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_PROVIDER-SERVICE/fc2ce9a6faaa:Provider-Service:8082: registering service...
emailservice     | 2026-01-04T16:52:00.576Z  INFO 1 --- [Email-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
apigateway       | 2026-01-04T16:52:00.586Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
apigateway       | 2026-01-04T16:52:00.605Z  INFO 1 --- [Api-Gateway] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
apigateway       | 2026-01-04T16:52:00.650Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway       | 2026-01-04T16:52:00.650Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway       | 2026-01-04T16:52:00.653Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway       | 2026-01-04T16:52:00.653Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
policyservice    | 2026-01-04T16:52:00.651Z  INFO 1 --- [Policy-Service] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
policyservice    | 	Database JDBC URL [jdbc:mysql://sqldb:3306/PolicyDB?createDatabaseIfNotExist=true&allowPublicKeyRetrieval=true&useSSL=false]
policyservice    | 	Database driver: MySQL Connector/J
policyservice    | 	Database dialect: MySQLDialect
policyservice    | 	Database version: 9.5
policyservice    | 	Default catalog/schema: PolicyDB/undefined
policyservice    | 	Autocommit mode: undefined/unknown
policyservice    | 	Isolation level: REPEATABLE_READ [default REPEATABLE_READ]
policyservice    | 	JDBC fetch size: none
policyservice    | 	Pool: DataSourceConnectionProvider
policyservice    | 	Minimum pool size: undefined/unknown
policyservice    | 	Maximum pool size: undefined/unknown
apigateway       | 2026-01-04T16:52:00.654Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway       | 2026-01-04T16:52:00.655Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
apigateway       | 2026-01-04T16:52:00.656Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
providerservice  | 2026-01-04T16:52:00.666Z  INFO 1 --- [Provider-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8082 (http) with context path '/'
providerservice  | 2026-01-04T16:52:00.689Z  INFO 1 --- [Provider-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8082
emailservice     | 2026-01-04T16:52:00.760Z  WARN 1 --- [Email-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
providerservice  | 2026-01-04T16:52:00.786Z  INFO 1 --- [Provider-Service] [           main] o.e.p.ProviderServiceApplication         : Started ProviderServiceApplication in 31.591 seconds (process running for 33.672)
identityservice  | 2026-01-04T16:52:00.967Z  WARN 1 --- [Identity-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
emailservice     | 2026-01-04T16:52:01.164Z  INFO 1 --- [Email-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
identityservice  | 2026-01-04T16:52:01.186Z  INFO 1 --- [Identity-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eureka           | 2026-01-04T16:52:01.196Z  INFO 1 --- [Service-Registry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance PROVIDER-SERVICE/fc2ce9a6faaa:Provider-Service:8082 with status UP (replication=false)
providerservice  | 2026-01-04T16:52:01.243Z  INFO 1 --- [Provider-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_PROVIDER-SERVICE/fc2ce9a6faaa:Provider-Service:8082 - registration status: 204
emailservice     | 2026-01-04T16:52:01.298Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
emailservice     | 2026-01-04T16:52:01.328Z  INFO 1 --- [Email-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
emailservice     | 2026-01-04T16:52:01.379Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
identityservice  | 2026-01-04T16:52:01.367Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
emailservice     | 2026-01-04T16:52:01.383Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice     | 2026-01-04T16:52:01.391Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice     | 2026-01-04T16:52:01.393Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice     | 2026-01-04T16:52:01.395Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice     | 2026-01-04T16:52:01.400Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
emailservice     | 2026-01-04T16:52:01.403Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
identityservice  | 2026-01-04T16:52:01.396Z  INFO 1 --- [Identity-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
identityservice  | 2026-01-04T16:52:01.457Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
identityservice  | 2026-01-04T16:52:01.460Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
identityservice  | 2026-01-04T16:52:01.461Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
identityservice  | 2026-01-04T16:52:01.463Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
identityservice  | 2026-01-04T16:52:01.463Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
identityservice  | 2026-01-04T16:52:01.467Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
identityservice  | 2026-01-04T16:52:01.470Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
apigateway       | 2026-01-04T16:52:01.998Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
apigateway       | 2026-01-04T16:52:02.007Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
apigateway       | 2026-01-04T16:52:02.028Z  INFO 1 --- [Api-Gateway] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
apigateway       | 2026-01-04T16:52:02.035Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545522034 with initial instances count: 0
apigateway       | 2026-01-04T16:52:02.043Z  INFO 1 --- [Api-Gateway] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application API-GATEWAY with eureka with status UP
apigateway       | 2026-01-04T16:52:02.045Z  INFO 1 --- [Api-Gateway] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545522045, current=UP, previous=STARTING]
apigateway       | 2026-01-04T16:52:02.056Z  INFO 1 --- [Api-Gateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_API-GATEWAY/699caaac306a:Api-Gateway:9000: registering service...
eureka           | 2026-01-04T16:52:02.226Z  INFO 1 --- [Service-Registry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance API-GATEWAY/699caaac306a:Api-Gateway:9000 with status UP (replication=false)
apigateway       | 2026-01-04T16:52:02.231Z  INFO 1 --- [Api-Gateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_API-GATEWAY/699caaac306a:Api-Gateway:9000 - registration status: 204
billingservice   | 2026-01-04T16:52:02.362Z  INFO 1 --- [Billing-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
eureka           | 2026-01-04T16:52:02.427Z  INFO 1 --- [Service-Registry] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance PROVIDER-SERVICE/fc2ce9a6faaa:Provider-Service:8082 with status UP (replication=true)
billingservice   | 2026-01-04T16:52:02.486Z  WARN 1 --- [Billing-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
apigateway       | 2026-01-04T16:52:02.718Z  INFO 1 --- [Api-Gateway] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 9000 (http)
billingservice   | 2026-01-04T16:52:02.718Z  INFO 1 --- [Billing-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
apigateway       | 2026-01-04T16:52:02.721Z  INFO 1 --- [Api-Gateway] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9000
eureka           | 2026-01-04T16:52:02.750Z  INFO 1 --- [Service-Registry] [nio-8761-exec-5] c.n.e.registry.AbstractInstanceRegistry  : Registered instance API-GATEWAY/699caaac306a:Api-Gateway:9000 with status UP (replication=true)
billingservice   | 2026-01-04T16:52:02.831Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
apigateway       | 2026-01-04T16:52:02.857Z  INFO 1 --- [Api-Gateway] [           main] o.e.apigateway.ApiGatewayApplication     : Started ApiGatewayApplication in 32.359 seconds (process running for 34.802)
billingservice   | 2026-01-04T16:52:02.864Z  INFO 1 --- [Billing-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
billingservice   | 2026-01-04T16:52:02.902Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
billingservice   | 2026-01-04T16:52:02.903Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
claimsservice    | 2026-01-04T16:52:02.980Z  INFO 1 --- [Claims-Service] [           main] org.hibernate.orm.core                   : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
identityservice  | 2026-01-04T16:52:03.046Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice     | 2026-01-04T16:52:03.047Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice     | 2026-01-04T16:52:03.054Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
identityservice  | 2026-01-04T16:52:03.058Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
emailservice     | 2026-01-04T16:52:03.067Z  INFO 1 --- [Email-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
identityservice  | 2026-01-04T16:52:03.069Z  INFO 1 --- [Identity-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
emailservice     | 2026-01-04T16:52:03.074Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545523072 with initial instances count: 0
identityservice  | 2026-01-04T16:52:03.081Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545523079 with initial instances count: 0
emailservice     | 2026-01-04T16:52:03.087Z  INFO 1 --- [Email-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application EMAIL-SERVICE with eureka with status UP
emailservice     | 2026-01-04T16:52:03.090Z  INFO 1 --- [Email-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545523090, current=UP, previous=STARTING]
emailservice     | 2026-01-04T16:52:03.099Z  INFO 1 --- [Email-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAIL-SERVICE/53e2f8a44fd7:Email-Service:8085: registering service...
identityservice  | 2026-01-04T16:52:03.102Z  INFO 1 --- [Identity-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application IDENTITY-SERVICE with eureka with status UP
identityservice  | 2026-01-04T16:52:03.106Z  INFO 1 --- [Identity-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545523106, current=UP, previous=STARTING]
identityservice  | 2026-01-04T16:52:03.117Z  INFO 1 --- [Identity-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_IDENTITY-SERVICE/d2133edb329a:Identity-Service: registering service...
emailservice     | 2026-01-04T16:52:03.145Z  INFO 1 --- [Email-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8085 (http) with context path '/'
emailservice     | 2026-01-04T16:52:03.147Z  INFO 1 --- [Email-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8085
identityservice  | 2026-01-04T16:52:03.176Z  INFO 1 --- [Identity-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8080 (http) with context path '/'
identityservice  | 2026-01-04T16:52:03.180Z  INFO 1 --- [Identity-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8080
identityservice  | 2026-01-04T16:52:03.243Z  INFO 1 --- [Identity-Service] [           main] o.e.i.IdentityServiceApplication         : Started IdentityServiceApplication in 33.82 seconds (process running for 36.055)
claimsservice    | 2026-01-04T16:52:03.233Z  INFO 1 --- [Claims-Service] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
eureka           | 2026-01-04T16:52:03.298Z  INFO 1 --- [Service-Registry] [nio-8761-exec-6] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAIL-SERVICE/53e2f8a44fd7:Email-Service:8085 with status UP (replication=false)
emailservice     | 2026-01-04T16:52:03.307Z  INFO 1 --- [Email-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAIL-SERVICE/53e2f8a44fd7:Email-Service:8085 - registration status: 204
eureka           | 2026-01-04T16:52:03.343Z  INFO 1 --- [Service-Registry] [nio-8761-exec-7] c.n.e.registry.AbstractInstanceRegistry  : Registered instance IDENTITY-SERVICE/d2133edb329a:Identity-Service with status UP (replication=false)
identityservice  | 2026-01-04T16:52:03.348Z  INFO 1 --- [Identity-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_IDENTITY-SERVICE/d2133edb329a:Identity-Service - registration status: 204
emailservice     | 2026-01-04T16:52:03.417Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-1
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:03.521Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
claimsservice    | 2026-01-04T16:52:03.543Z  INFO 1 --- [Claims-Service] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
billingservice   | 2026-01-04T16:52:03.805Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
billingservice   | 2026-01-04T16:52:03.811Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
eureka           | 2026-01-04T16:52:03.815Z  INFO 1 --- [Service-Registry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAIL-SERVICE/53e2f8a44fd7:Email-Service:8085 with status UP (replication=true)
eureka           | 2026-01-04T16:52:03.816Z  INFO 1 --- [Service-Registry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance IDENTITY-SERVICE/d2133edb329a:Identity-Service with status UP (replication=true)
billingservice   | 2026-01-04T16:52:03.822Z  INFO 1 --- [Billing-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
billingservice   | 2026-01-04T16:52:03.828Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545523827 with initial instances count: 0
billingservice   | 2026-01-04T16:52:03.841Z  INFO 1 --- [Billing-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application BILLING-SERVICE with eureka with status UP
billingservice   | 2026-01-04T16:52:03.844Z  INFO 1 --- [Billing-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545523844, current=UP, previous=STARTING]
billingservice   | 2026-01-04T16:52:03.848Z  INFO 1 --- [Billing-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BILLING-SERVICE/d569f1f3570e:Billing-Service:8084: registering service...
billingservice   | 2026-01-04T16:52:03.901Z  INFO 1 --- [Billing-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8084 (http) with context path '/'
billingservice   | 2026-01-04T16:52:03.903Z  INFO 1 --- [Billing-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8084
eureka           | 2026-01-04T16:52:03.980Z  INFO 1 --- [Service-Registry] [io-8761-exec-10] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BILLING-SERVICE/d569f1f3570e:Billing-Service:8084 with status UP (replication=false)
billingservice   | 2026-01-04T16:52:03.985Z  INFO 1 --- [Billing-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BILLING-SERVICE/d569f1f3570e:Billing-Service:8084 - registration status: 204
billingservice   | 2026-01-04T16:52:03.999Z  INFO 1 --- [Billing-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
billingservice   | 	allow.auto.create.topics = true
billingservice   | 	auto.commit.interval.ms = 5000
billingservice   | 	auto.offset.reset = latest
billingservice   | 	bootstrap.servers = [kafkaQueue:9092]
billingservice   | 	check.crcs = true
billingservice   | 	client.dns.lookup = use_all_dns_ips
billingservice   | 	client.id = consumer-billing-service-group-1
billingservice   | 	client.rack = 
billingservice   | 	connections.max.idle.ms = 540000
billingservice   | 	default.api.timeout.ms = 60000
billingservice   | 	enable.auto.commit = false
billingservice   | 	enable.metrics.push = true
billingservice   | 	exclude.internal.topics = true
billingservice   | 	fetch.max.bytes = 52428800
billingservice   | 	fetch.max.wait.ms = 500
billingservice   | 	fetch.min.bytes = 1
billingservice   | 	group.id = billing-service-group
billingservice   | 	group.instance.id = null
billingservice   | 	group.protocol = classic
billingservice   | 	group.remote.assignor = null
billingservice   | 	heartbeat.interval.ms = 3000
billingservice   | 	interceptor.classes = []
billingservice   | 	internal.leave.group.on.close = true
billingservice   | 	internal.throw.on.fetch.stable.offset.unsupported = false
billingservice   | 	isolation.level = read_uncommitted
billingservice   | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
billingservice   | 	max.partition.fetch.bytes = 1048576
billingservice   | 	max.poll.interval.ms = 300000
billingservice   | 	max.poll.records = 500
billingservice   | 	metadata.max.age.ms = 300000
billingservice   | 	metadata.recovery.rebootstrap.trigger.ms = 300000
billingservice   | 	metadata.recovery.strategy = rebootstrap
billingservice   | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
billingservice   | 	metrics.num.samples = 2
billingservice   | 	metrics.recording.level = INFO
billingservice   | 	metrics.sample.window.ms = 30000
billingservice   | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
billingservice   | 	receive.buffer.bytes = 65536
billingservice   | 	reconnect.backoff.max.ms = 1000
billingservice   | 	reconnect.backoff.ms = 50
billingservice   | 	request.timeout.ms = 30000
billingservice   | 	retry.backoff.max.ms = 1000
billingservice   | 	retry.backoff.ms = 100
billingservice   | 	sasl.client.callback.handler.class = null
billingservice   | 	sasl.jaas.config = null
billingservice   | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
billingservice   | 	sasl.kerberos.min.time.before.relogin = 60000
billingservice   | 	sasl.kerberos.service.name = null
billingservice   | 	sasl.kerberos.ticket.renew.jitter = 0.05
billingservice   | 	sasl.kerberos.ticket.renew.window.factor = 0.8
billingservice   | 	sasl.login.callback.handler.class = null
billingservice   | 	sasl.login.class = null
billingservice   | 	sasl.login.connect.timeout.ms = null
billingservice   | 	sasl.login.read.timeout.ms = null
billingservice   | 	sasl.login.refresh.buffer.seconds = 300
billingservice   | 	sasl.login.refresh.min.period.seconds = 60
billingservice   | 	sasl.login.refresh.window.factor = 0.8
billingservice   | 	sasl.login.refresh.window.jitter = 0.05
billingservice   | 	sasl.login.retry.backoff.max.ms = 10000
billingservice   | 	sasl.login.retry.backoff.ms = 100
billingservice   | 	sasl.mechanism = GSSAPI
billingservice   | 	sasl.oauthbearer.assertion.algorithm = RS256
billingservice   | 	sasl.oauthbearer.assertion.claim.aud = null
billingservice   | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
billingservice   | 	sasl.oauthbearer.assertion.claim.iss = null
billingservice   | 	sasl.oauthbearer.assertion.claim.jti.include = false
billingservice   | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
billingservice   | 	sasl.oauthbearer.assertion.claim.sub = null
billingservice   | 	sasl.oauthbearer.assertion.file = null
billingservice   | 	sasl.oauthbearer.assertion.private.key.file = null
billingservice   | 	sasl.oauthbearer.assertion.private.key.passphrase = null
billingservice   | 	sasl.oauthbearer.assertion.template.file = null
billingservice   | 	sasl.oauthbearer.client.credentials.client.id = null
billingservice   | 	sasl.oauthbearer.client.credentials.client.secret = null
billingservice   | 	sasl.oauthbearer.clock.skew.seconds = 30
billingservice   | 	sasl.oauthbearer.expected.audience = null
billingservice   | 	sasl.oauthbearer.expected.issuer = null
billingservice   | 	sasl.oauthbearer.header.urlencode = false
billingservice   | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
billingservice   | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
billingservice   | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
billingservice   | 	sasl.oauthbearer.jwks.endpoint.url = null
billingservice   | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
billingservice   | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
billingservice   | 	sasl.oauthbearer.scope = null
billingservice   | 	sasl.oauthbearer.scope.claim.name = scope
billingservice   | 	sasl.oauthbearer.sub.claim.name = sub
billingservice   | 	sasl.oauthbearer.token.endpoint.url = null
billingservice   | 	security.protocol = PLAINTEXT
billingservice   | 	security.providers = null
billingservice   | 	send.buffer.bytes = 131072
billingservice   | 	session.timeout.ms = 45000
billingservice   | 	share.acknowledgement.mode = implicit
billingservice   | 	socket.connection.setup.timeout.max.ms = 30000
billingservice   | 	socket.connection.setup.timeout.ms = 10000
billingservice   | 	ssl.cipher.suites = null
billingservice   | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
billingservice   | 	ssl.endpoint.identification.algorithm = https
billingservice   | 	ssl.engine.factory.class = null
billingservice   | 	ssl.key.password = null
billingservice   | 	ssl.keymanager.algorithm = SunX509
billingservice   | 	ssl.keystore.certificate.chain = null
billingservice   | 	ssl.keystore.key = null
billingservice   | 	ssl.keystore.location = null
billingservice   | 	ssl.keystore.password = null
billingservice   | 	ssl.keystore.type = JKS
billingservice   | 	ssl.protocol = TLSv1.3
billingservice   | 	ssl.provider = null
billingservice   | 	ssl.secure.random.implementation = null
billingservice   | 	ssl.trustmanager.algorithm = PKIX
billingservice   | 	ssl.truststore.certificates = null
billingservice   | 	ssl.truststore.location = null
billingservice   | 	ssl.truststore.password = null
billingservice   | 	ssl.truststore.type = JKS
billingservice   | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
billingservice   | 
emailservice     | 2026-01-04T16:52:04.062Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.063Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.064Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524056
emailservice     | 2026-01-04T16:52:04.076Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Subscribed to topic(s): claim-submission-email
emailservice     | 2026-01-04T16:52:04.106Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-2
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.107Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
billingservice   | 2026-01-04T16:52:04.134Z  INFO 1 --- [Billing-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.151Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.152Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.152Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524151
emailservice     | 2026-01-04T16:52:04.155Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Subscribed to topic(s): payout-email
policyservice    | 2026-01-04T16:52:04.158Z  INFO 1 --- [Policy-Service] [           main] org.hibernate.orm.core                   : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
emailservice     | 2026-01-04T16:52:04.161Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-3
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.163Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.188Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.189Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.190Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524188
emailservice     | 2026-01-04T16:52:04.193Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Subscribed to topic(s): policy-purchase-email
emailservice     | 2026-01-04T16:52:04.199Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-4
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.202Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.219Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.219Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.220Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524219
emailservice     | 2026-01-04T16:52:04.223Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Subscribed to topic(s): otp-email
emailservice     | 2026-01-04T16:52:04.231Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-5
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.232Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.254Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.254Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.255Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524254
emailservice     | 2026-01-04T16:52:04.260Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Subscribed to topic(s): account-activation-email
emailservice     | 2026-01-04T16:52:04.268Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-6
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.269Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.277Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.278Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.278Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524277
emailservice     | 2026-01-04T16:52:04.279Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Subscribed to topic(s): claim-decision-email
emailservice     | 2026-01-04T16:52:04.286Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice     | 	allow.auto.create.topics = true
emailservice     | 	auto.commit.interval.ms = 5000
emailservice     | 	auto.offset.reset = latest
emailservice     | 	bootstrap.servers = [kafkaQueue:9092]
emailservice     | 	check.crcs = true
emailservice     | 	client.dns.lookup = use_all_dns_ips
emailservice     | 	client.id = consumer-email-service-group-7
emailservice     | 	client.rack = 
emailservice     | 	connections.max.idle.ms = 540000
emailservice     | 	default.api.timeout.ms = 60000
emailservice     | 	enable.auto.commit = false
emailservice     | 	enable.metrics.push = true
emailservice     | 	exclude.internal.topics = true
emailservice     | 	fetch.max.bytes = 52428800
emailservice     | 	fetch.max.wait.ms = 500
emailservice     | 	fetch.min.bytes = 1
emailservice     | 	group.id = email-service-group
emailservice     | 	group.instance.id = null
emailservice     | 	group.protocol = classic
emailservice     | 	group.remote.assignor = null
emailservice     | 	heartbeat.interval.ms = 3000
emailservice     | 	interceptor.classes = []
emailservice     | 	internal.leave.group.on.close = true
emailservice     | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice     | 	isolation.level = read_uncommitted
emailservice     | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice     | 	max.partition.fetch.bytes = 1048576
emailservice     | 	max.poll.interval.ms = 300000
emailservice     | 	max.poll.records = 500
emailservice     | 	metadata.max.age.ms = 300000
emailservice     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice     | 	metadata.recovery.strategy = rebootstrap
emailservice     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice     | 	metrics.num.samples = 2
emailservice     | 	metrics.recording.level = INFO
emailservice     | 	metrics.sample.window.ms = 30000
emailservice     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice     | 	receive.buffer.bytes = 65536
emailservice     | 	reconnect.backoff.max.ms = 1000
emailservice     | 	reconnect.backoff.ms = 50
emailservice     | 	request.timeout.ms = 30000
emailservice     | 	retry.backoff.max.ms = 1000
emailservice     | 	retry.backoff.ms = 100
emailservice     | 	sasl.client.callback.handler.class = null
emailservice     | 	sasl.jaas.config = null
emailservice     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice     | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice     | 	sasl.kerberos.service.name = null
emailservice     | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice     | 	sasl.login.callback.handler.class = null
emailservice     | 	sasl.login.class = null
emailservice     | 	sasl.login.connect.timeout.ms = null
emailservice     | 	sasl.login.read.timeout.ms = null
emailservice     | 	sasl.login.refresh.buffer.seconds = 300
emailservice     | 	sasl.login.refresh.min.period.seconds = 60
emailservice     | 	sasl.login.refresh.window.factor = 0.8
emailservice     | 	sasl.login.refresh.window.jitter = 0.05
emailservice     | 	sasl.login.retry.backoff.max.ms = 10000
emailservice     | 	sasl.login.retry.backoff.ms = 100
emailservice     | 	sasl.mechanism = GSSAPI
emailservice     | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice     | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice     | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice     | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice     | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice     | 	sasl.oauthbearer.assertion.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice     | 	sasl.oauthbearer.assertion.template.file = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice     | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice     | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice     | 	sasl.oauthbearer.expected.audience = null
emailservice     | 	sasl.oauthbearer.expected.issuer = null
emailservice     | 	sasl.oauthbearer.header.urlencode = false
emailservice     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice     | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice     | 	sasl.oauthbearer.scope = null
emailservice     | 	sasl.oauthbearer.scope.claim.name = scope
emailservice     | 	sasl.oauthbearer.sub.claim.name = sub
emailservice     | 	sasl.oauthbearer.token.endpoint.url = null
emailservice     | 	security.protocol = PLAINTEXT
emailservice     | 	security.providers = null
emailservice     | 	send.buffer.bytes = 131072
emailservice     | 	session.timeout.ms = 45000
emailservice     | 	share.acknowledgement.mode = implicit
emailservice     | 	socket.connection.setup.timeout.max.ms = 30000
emailservice     | 	socket.connection.setup.timeout.ms = 10000
emailservice     | 	ssl.cipher.suites = null
emailservice     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice     | 	ssl.endpoint.identification.algorithm = https
emailservice     | 	ssl.engine.factory.class = null
emailservice     | 	ssl.key.password = null
emailservice     | 	ssl.keymanager.algorithm = SunX509
emailservice     | 	ssl.keystore.certificate.chain = null
emailservice     | 	ssl.keystore.key = null
emailservice     | 	ssl.keystore.location = null
emailservice     | 	ssl.keystore.password = null
emailservice     | 	ssl.keystore.type = JKS
emailservice     | 	ssl.protocol = TLSv1.3
emailservice     | 	ssl.provider = null
emailservice     | 	ssl.secure.random.implementation = null
emailservice     | 	ssl.trustmanager.algorithm = PKIX
emailservice     | 	ssl.truststore.certificates = null
emailservice     | 	ssl.truststore.location = null
emailservice     | 	ssl.truststore.password = null
emailservice     | 	ssl.truststore.type = JKS
emailservice     | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice     | 
emailservice     | 2026-01-04T16:52:04.290Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice     | 2026-01-04T16:52:04.320Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice     | 2026-01-04T16:52:04.321Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice     | 2026-01-04T16:52:04.322Z  INFO 1 --- [Email-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524320
emailservice     | 2026-01-04T16:52:04.323Z  INFO 1 --- [Email-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Subscribed to topic(s): policy-renewal-reminder
emailservice     | 2026-01-04T16:52:04.375Z  INFO 1 --- [Email-Service] [           main] o.e.e.EmailServiceApplication            : Started EmailServiceApplication in 34.995 seconds (process running for 37.151)
policyservice    | 2026-01-04T16:52:04.387Z  INFO 1 --- [Policy-Service] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
eureka           | 2026-01-04T16:52:04.504Z  INFO 1 --- [Service-Registry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BILLING-SERVICE/d569f1f3570e:Billing-Service:8084 with status UP (replication=true)
policyservice    | 2026-01-04T16:52:04.823Z  INFO 1 --- [Policy-Service] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
billingservice   | 2026-01-04T16:52:04.859Z  INFO 1 --- [Billing-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
billingservice   | 2026-01-04T16:52:04.861Z  INFO 1 --- [Billing-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
billingservice   | 2026-01-04T16:52:04.861Z  INFO 1 --- [Billing-Service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1767545524853
billingservice   | 2026-01-04T16:52:04.876Z  INFO 1 --- [Billing-Service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Subscribed to topic(s): claim-payout
billingservice   | 2026-01-04T16:52:04.941Z  INFO 1 --- [Billing-Service] [           main] o.e.b.BillingServiceApplication          : Started BillingServiceApplication in 35.333 seconds (process running for 37.783)
emailservice     | 2026-01-04T16:52:05.534Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.534Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.534Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.536Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.538Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.538Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.540Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice     | 2026-01-04T16:52:05.547Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.547Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.547Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.548Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.550Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.550Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.552Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.553Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.554Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.555Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.554Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.557Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice     | 2026-01-04T16:52:05.559Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.560Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:05,600] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,604] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:05.606Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684
emailservice     | 2026-01-04T16:52:05.607Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b
kafkaQueue       | [2026-01-04 16:52:05,606] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,607] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:05.607Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:05,609] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:05.609Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.609Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f
emailservice     | 2026-01-04T16:52:05.610Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390
emailservice     | 2026-01-04T16:52:05.611Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.611Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:05,612] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,614] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Stable state. Created a new member id consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:05.615Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e
emailservice     | 2026-01-04T16:52:05.616Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:05,618] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684 joins group email-service-group in Stable state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:05.618Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215
emailservice     | 2026-01-04T16:52:05.619Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7
emailservice     | 2026-01-04T16:52:05.621Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice     | 2026-01-04T16:52:05.622Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:05,628] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Preparing to rebalance group email-service-group in state PreparingRebalance with old generation 1 (reason: Adding new member consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684 with group instance id null; client reason: need to re-join with the given member-id: consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684). (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,631] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,631] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,632] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,632] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,632] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:05,633] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
claimsservice    | 2026-01-04T16:52:05.850Z  WARN 1 --- [Claims-Service] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
claimsservice    | 2026-01-04T16:52:06.054Z  INFO 1 --- [Claims-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Policy-Service' URL not provided. Will try picking an instance via load-balancing.
claimsservice    | 2026-01-04T16:52:06.304Z  INFO 1 --- [Claims-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Provider-Service' URL not provided. Will try picking an instance via load-balancing.
claimsservice    | 2026-01-04T16:52:06.443Z  INFO 1 --- [Claims-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Identity-Service' URL not provided. Will try picking an instance via load-balancing.
billingservice   | 2026-01-04T16:52:06.499Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
billingservice   | 2026-01-04T16:52:06.516Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
billingservice   | 2026-01-04T16:52:06.524Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:06,582] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Dynamic member with unknown member id joins group billing-service-group in Stable state. Created a new member id consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
billingservice   | 2026-01-04T16:52:06.586Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Request joining group due to: need to re-join with the given member-id: consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47
billingservice   | 2026-01-04T16:52:06.587Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] (Re-)joining group
kafkaQueue       | [2026-01-04 16:52:06,591] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Pending dynamic member with id consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47 joins group billing-service-group in Stable state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:06,592] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Preparing to rebalance group billing-service-group in state PreparingRebalance with old generation 1 (reason: Adding new member consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47 with group instance id null; client reason: need to re-join with the given member-id: consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47). (org.apache.kafka.coordinator.group.GroupMetadataManager)
policyservice    | 2026-01-04T16:52:07.159Z  WARN 1 --- [Policy-Service] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
policyservice    | 2026-01-04T16:52:07.503Z  INFO 1 --- [Policy-Service] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'Identity-Service' URL not provided. Will try picking an instance via load-balancing.
claimsservice    | 2026-01-04T16:52:07.909Z  INFO 1 --- [Claims-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
claimsservice    | 2026-01-04T16:52:07.955Z  WARN 1 --- [Claims-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
claimsservice    | 2026-01-04T16:52:08.008Z  INFO 1 --- [Claims-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
claimsservice    | 2026-01-04T16:52:08.054Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
claimsservice    | 2026-01-04T16:52:08.064Z  INFO 1 --- [Claims-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
claimsservice    | 2026-01-04T16:52:08.083Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
policyservice    | 2026-01-04T16:52:08.707Z  INFO 1 --- [Policy-Service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
policyservice    | 2026-01-04T16:52:08.762Z  WARN 1 --- [Policy-Service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
claimsservice    | 2026-01-04T16:52:08.794Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
claimsservice    | 2026-01-04T16:52:08.796Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
claimsservice    | 2026-01-04T16:52:08.798Z  INFO 1 --- [Claims-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
claimsservice    | 2026-01-04T16:52:08.800Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545528799 with initial instances count: 0
claimsservice    | 2026-01-04T16:52:08.804Z  INFO 1 --- [Claims-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application CLAIMS-SERVICE with eureka with status UP
claimsservice    | 2026-01-04T16:52:08.806Z  INFO 1 --- [Claims-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545528806, current=UP, previous=STARTING]
claimsservice    | 2026-01-04T16:52:08.809Z  INFO 1 --- [Claims-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_CLAIMS-SERVICE/42039ba02854:Claims-Service:8083: registering service...
policyservice    | 2026-01-04T16:52:08.812Z  INFO 1 --- [Policy-Service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
claimsservice    | 2026-01-04T16:52:08.835Z  INFO 1 --- [Claims-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8083 (http) with context path '/'
claimsservice    | 2026-01-04T16:52:08.837Z  INFO 1 --- [Claims-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8083
policyservice    | 2026-01-04T16:52:08.856Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
policyservice    | 2026-01-04T16:52:08.862Z  INFO 1 --- [Policy-Service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
policyservice    | 2026-01-04T16:52:08.876Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
policyservice    | 2026-01-04T16:52:08.877Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eureka           | 2026-01-04T16:52:08.878Z  INFO 1 --- [Service-Registry] [nio-8761-exec-5] c.n.e.registry.AbstractInstanceRegistry  : Registered instance CLAIMS-SERVICE/42039ba02854:Claims-Service:8083 with status UP (replication=false)
claimsservice    | 2026-01-04T16:52:08.883Z  INFO 1 --- [Claims-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_CLAIMS-SERVICE/42039ba02854:Claims-Service:8083 - registration status: 204
claimsservice    | 2026-01-04T16:52:08.885Z  INFO 1 --- [Claims-Service] [           main] o.e.c.ClaimsServiceApplication           : Started ClaimsServiceApplication in 39.381 seconds (process running for 41.805)
policyservice    | 2026-01-04T16:52:09.342Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
policyservice    | 2026-01-04T16:52:09.343Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
policyservice    | 2026-01-04T16:52:09.345Z  INFO 1 --- [Policy-Service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
policyservice    | 2026-01-04T16:52:09.346Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1767545529346 with initial instances count: 0
policyservice    | 2026-01-04T16:52:09.349Z  INFO 1 --- [Policy-Service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application POLICY-SERVICE with eureka with status UP
policyservice    | 2026-01-04T16:52:09.350Z  INFO 1 --- [Policy-Service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1767545529350, current=UP, previous=STARTING]
policyservice    | 2026-01-04T16:52:09.351Z  INFO 1 --- [Policy-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_POLICY-SERVICE/e16343f228cd:Policy-Service:8081: registering service...
policyservice    | 2026-01-04T16:52:09.361Z  INFO 1 --- [Policy-Service] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8081 (http) with context path '/'
policyservice    | 2026-01-04T16:52:09.362Z  INFO 1 --- [Policy-Service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8081
policyservice    | 2026-01-04T16:52:09.377Z  INFO 1 --- [Policy-Service] [           main] o.e.p.PolicyServiceApplication           : Started PolicyServiceApplication in 40.484 seconds (process running for 42.343)
eureka           | 2026-01-04T16:52:09.384Z  INFO 1 --- [Service-Registry] [nio-8761-exec-7] c.n.e.registry.AbstractInstanceRegistry  : Registered instance CLAIMS-SERVICE/42039ba02854:Claims-Service:8083 with status UP (replication=true)
eureka           | 2026-01-04T16:52:09.402Z  INFO 1 --- [Service-Registry] [nio-8761-exec-8] c.n.e.registry.AbstractInstanceRegistry  : Registered instance POLICY-SERVICE/e16343f228cd:Policy-Service:8081 with status UP (replication=false)
policyservice    | 2026-01-04T16:52:09.404Z  INFO 1 --- [Policy-Service] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_POLICY-SERVICE/e16343f228cd:Policy-Service:8081 - registration status: 204
eureka           | 2026-01-04T16:52:09.911Z  INFO 1 --- [Service-Registry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance POLICY-SERVICE/e16343f228cd:Policy-Service:8081 with status UP (replication=true)
kafkaQueue       | [2026-01-04 16:52:15,830] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-7-c4247b20-5551-427f-bf26-c0b917d3db80 in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-2-adfa2e41-f6a1-4e84-b720-ae005b58c6e8 in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-6-ac6e1a15-5859-4359-b92c-672e209757f8 in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-4-321267dc-a0a8-4933-bb4c-0f94ab94fb7a in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-5-820dd14f-15e3-4ceb-a7c7-c5d5b82616ec in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-3-7522e227-ff03-4d43-b656-8efdedc561de in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,831] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Member consumer-email-service-group-1-0f1f47d6-a525-436c-b68d-ac033de8c71a in group email-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,832] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Stabilized group email-service-group generation 2 with 7 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b', protocol='range'}
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7', protocol='range'}
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f', protocol='range'}
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215', protocol='range'}
emailservice     | 2026-01-04T16:52:15.835Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390', protocol='range'}
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e', protocol='range'}
emailservice     | 2026-01-04T16:52:15.834Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684', protocol='range'}
emailservice     | 2026-01-04T16:52:15.844Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Finished assignment for group at generation 2: {consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b=Assignment(partitions=[account-activation-email-0]), consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e=Assignment(partitions=[otp-email-0]), consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215=Assignment(partitions=[payout-email-0]), consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f=Assignment(partitions=[policy-renewal-reminder-0]), consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390=Assignment(partitions=[claim-submission-email-0]), consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7=Assignment(partitions=[policy-purchase-email-0]), consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684=Assignment(partitions=[claim-decision-email-0])}
kafkaQueue       | [2026-01-04 16:52:15,848] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Assignment received from leader consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b for group email-service-group for generation 2. The group has 7 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-7-d93f3756-5a21-461c-b487-9899771d248f', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-2-6b6690fb-579f-49c8-b155-3f5a6a8e4215', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-6-e0a95eb0-da8a-4f59-b642-77d06347b684', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-5-7818abe7-f3cc-4d94-a1d6-4bdf2922b78b', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-4-a9f8fd21-4ea0-4cac-b556-df9f4c34794e', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-3-c371258c-dd0f-4148-958a-13f92d7908a7', protocol='range'}
emailservice     | 2026-01-04T16:52:15.861Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-email-service-group-1-1c10c384-3198-4e6a-bfbe-ba60b304d390', protocol='range'}
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[policy-renewal-reminder-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[claim-decision-email-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[claim-submission-email-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[account-activation-email-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[payout-email-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[otp-email-0])
emailservice     | 2026-01-04T16:52:15.862Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[policy-purchase-email-0])
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Adding newly assigned partitions: [policy-purchase-email-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Adding newly assigned partitions: [claim-submission-email-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-7, groupId=email-service-group] Adding newly assigned partitions: [policy-renewal-reminder-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-6, groupId=email-service-group] Adding newly assigned partitions: [claim-decision-email-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-4, groupId=email-service-group] Adding newly assigned partitions: [otp-email-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-5, groupId=email-service-group] Adding newly assigned partitions: [account-activation-email-0]
emailservice     | 2026-01-04T16:52:15.863Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Adding newly assigned partitions: [payout-email-0]
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition claim-decision-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition otp-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition policy-renewal-reminder-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition payout-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition account-activation-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition claim-submission-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.877Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition policy-purchase-email-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [otp-email-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [claim-decision-email-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [account-activation-email-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [policy-renewal-reminder-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [payout-email-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [claim-submission-email-0]
emailservice     | 2026-01-04T16:52:15.880Z  INFO 1 --- [Email-Service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [policy-purchase-email-0]
kafkaQueue       | [2026-01-04 16:52:15,910] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Member consumer-billing-service-group-1-de244188-370b-4f24-b0c7-4f309aafb89d in group billing-service-group has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue       | [2026-01-04 16:52:15,911] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Stabilized group billing-service-group generation 2 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
billingservice   | 2026-01-04T16:52:15.914Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47', protocol='range'}
billingservice   | 2026-01-04T16:52:15.920Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Finished assignment for group at generation 2: {consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47=Assignment(partitions=[claim-payout-0])}
kafkaQueue       | [2026-01-04 16:52:15,923] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Assignment received from leader consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47 for group billing-service-group for generation 2. The group has 1 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
billingservice   | 2026-01-04T16:52:15.930Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-billing-service-group-1-fce59220-a689-44c7-bb6d-bda6645bdc47', protocol='range'}
billingservice   | 2026-01-04T16:52:15.931Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Notifying assignor about the new Assignment(partitions=[claim-payout-0])
billingservice   | 2026-01-04T16:52:15.933Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-billing-service-group-1, groupId=billing-service-group] Adding newly assigned partitions: [claim-payout-0]
billingservice   | 2026-01-04T16:52:15.941Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils        : Setting offset for partition claim-payout-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=4}}
billingservice   | 2026-01-04T16:52:15.943Z  INFO 1 --- [Billing-Service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : billing-service-group: partitions assigned: [claim-payout-0]
mongo            | {"t":{"$date":"2026-01-04T16:52:17.991+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545537,"ts_usec":991762,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 6, snapshot max: 6 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
claimsservice    | 2026-01-04T16:52:22.968Z  INFO 1 --- [Claims-Service] [nio-8083-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
claimsservice    | 2026-01-04T16:52:22.968Z  INFO 1 --- [Claims-Service] [nio-8083-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
claimsservice    | 2026-01-04T16:52:22.969Z  INFO 1 --- [Claims-Service] [nio-8083-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
claimsservice    | Hibernate: select c1_0.id,c1_0.claim_request_date,c1_0.officer_review_id,c1_0.hospital_id,c1_0.policy_id,c1_0.provider_review_id,c1_0.requested_amount,c1_0.stage,c1_0.status,c1_0.submitted_by,c1_0.supporting_document,c1_0.user_id from claim c1_0 where c1_0.hospital_id=? order by c1_0.claim_request_date limit ?,?
claimsservice    | Hibernate: select count(c1_0.id) from claim c1_0 where c1_0.hospital_id=?
claimsservice    | 2026-01-04T16:52:23.134Z  WARN 1 --- [Claims-Service] [nio-8083-exec-2] ration$PageModule$WarningLoggingModifier : Serializing PageImpl instances as-is is not supported, meaning that there is no guarantee about the stability of the resulting JSON structure!
claimsservice    | 	For a stable JSON structure, please use Spring Data's PagedModel (globally via @EnableSpringDataWebSupport(pageSerializationMode = VIA_DTO))
claimsservice    | 	or Spring HATEOAS and Spring Data's PagedResourcesAssembler as documented in https://docs.spring.io/spring-data/commons/reference/repositories/core-extensions.html#core.web.pageables.
claimsservice    | 
eureka           | 2026-01-04T16:52:23.444Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
providerservice  | 2026-01-04T16:52:30.464Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
providerservice  | 2026-01-04T16:52:30.465Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
providerservice  | 2026-01-04T16:52:30.480Z  INFO 1 --- [Provider-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
apigateway       | 2026-01-04T16:52:32.006Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway       | 2026-01-04T16:52:32.006Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway       | 2026-01-04T16:52:32.006Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway       | 2026-01-04T16:52:32.006Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway       | 2026-01-04T16:52:32.007Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway       | 2026-01-04T16:52:32.007Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
apigateway       | 2026-01-04T16:52:32.007Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
apigateway       | 2026-01-04T16:52:32.020Z  INFO 1 --- [Api-Gateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice     | 2026-01-04T16:52:33.053Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
emailservice     | 2026-01-04T16:52:33.054Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
identityservice  | 2026-01-04T16:52:33.055Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
emailservice     | 2026-01-04T16:52:33.069Z  INFO 1 --- [Email-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
identityservice  | 2026-01-04T16:52:33.074Z  INFO 1 --- [Identity-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
billingservice   | 2026-01-04T16:52:33.811Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
billingservice   | 2026-01-04T16:52:33.826Z  INFO 1 --- [Billing-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
claimsservice    | Hibernate: select c1_0.id,c1_0.claim_request_date,c1_0.officer_review_id,c1_0.hospital_id,c1_0.policy_id,c1_0.provider_review_id,c1_0.requested_amount,c1_0.stage,c1_0.status,c1_0.submitted_by,c1_0.supporting_document,c1_0.user_id from claim c1_0 where c1_0.hospital_id=? order by c1_0.claim_request_date limit ?,?
claimsservice    | Hibernate: select count(c1_0.id) from claim c1_0 where c1_0.hospital_id=?
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
claimsservice    | 2026-01-04T16:52:38.796Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
claimsservice    | 2026-01-04T16:52:38.814Z  INFO 1 --- [Claims-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
policyservice    | 2026-01-04T16:52:39.343Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
policyservice    | 2026-01-04T16:52:39.344Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
policyservice    | 2026-01-04T16:52:39.358Z  INFO 1 --- [Policy-Service] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
claimsservice    | Hibernate: select c1_0.id,c1_0.claim_request_date,c1_0.officer_review_id,c1_0.hospital_id,c1_0.policy_id,c1_0.provider_review_id,c1_0.requested_amount,c1_0.stage,c1_0.status,c1_0.submitted_by,c1_0.supporting_document,c1_0.user_id from claim c1_0 where c1_0.hospital_id=? order by c1_0.claim_request_date limit ?,?
claimsservice    | Hibernate: select cr1_0.id,cr1_0.comments,cr1_0.review_date,cr1_0.review_status,cr1_0.reviewer_role,cr1_0.user_id from claim_review cr1_0 where cr1_0.id=?
claimsservice    | Hibernate: select count(c1_0.id) from claim c1_0 where c1_0.hospital_id=?
claimsservice    | Hibernate: select c1_0.id,c1_0.claim_request_date,c1_0.officer_review_id,c1_0.hospital_id,c1_0.policy_id,c1_0.provider_review_id,c1_0.requested_amount,c1_0.stage,c1_0.status,c1_0.submitted_by,c1_0.supporting_document,c1_0.user_id from claim c1_0 where c1_0.hospital_id=? order by c1_0.claim_request_date limit ?,?
mongo            | {"t":{"$date":"2026-01-04T16:53:18.003+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545598,"ts_usec":3715,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 8, snapshot max: 8 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
eureka           | 2026-01-04T16:53:23.444Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
claimsservice    | 2026-01-04T16:53:30.113Z ERROR 1 --- [Claims-Service] [nio-8083-exec-6] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: org.springframework.dao.InvalidDataAccessApiUsageException: Argument to query parameter has an incompatible type (java.time.LocalDate is not assignable to java.time.LocalDateTime)] with root cause
claimsservice    | 
claimsservice    | org.hibernate.query.QueryArgumentException: Argument to query parameter has an incompatible type (java.time.LocalDate is not assignable to java.time.LocalDateTime)
claimsservice    | 	at org.hibernate.query.spi.AbstractCommonQueryContract.setParameterValue(AbstractCommonQueryContract.java:881) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.spi.AbstractCommonQueryContract.setParameter(AbstractCommonQueryContract.java:907) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.spi.AbstractSelectionQuery.setParameter(AbstractSelectionQuery.java:651) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.sqm.internal.SqmQueryImpl.setParameter(SqmQueryImpl.java:1049) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.sqm.internal.SqmQueryImpl.setParameter(SqmQueryImpl.java:109) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$BindableQuery.setParameter(QueryParameterSetter.java:303) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$NamedOrIndexedQueryParameterSetter.setParameter(QueryParameterSetter.java:107) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$NamedOrIndexedQueryParameterSetter.setParameter(QueryParameterSetter.java:95) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bind(ParameterBinder.java:87) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bind(ParameterBinder.java:79) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bindAndPrepare(ParameterBinder.java:100) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery$QueryPreparer.invokeBinding(PartTreeJpaQuery.java:368) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery$QueryPreparer.createQuery(PartTreeJpaQuery.java:250) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.doCreateQuery(PartTreeJpaQuery.java:125) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.createQuery(AbstractJpaQuery.java:264) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.JpaQueryExecution$PagedExecution.doExecute(JpaQueryExecution.java:285) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.JpaQueryExecution.execute(JpaQueryExecution.java:99) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.doExecute(AbstractJpaQuery.java:164) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.execute(AbstractJpaQuery.java:154) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:169) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:167) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:146) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:370) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:135) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:137) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:222) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jdk.proxy2/jdk.proxy2.$Proxy149.findByClaimRequestDateBetweenOrderByRequestedAmountDesc(Unknown Source) ~[na:na]
claimsservice    | 	at org.example.claimsservice.service.Implementation.AnalyticServiceImpl.getTopHighValueClaimsLastMonth(AnalyticServiceImpl.java:43) ~[!/:0.0.1-SNAPSHOT]
claimsservice    | 	at org.example.claimsservice.controller.AnalyticController.getHighValueClaimsLastMonth(AnalyticController.java:40) ~[!/:0.0.1-SNAPSHOT]
claimsservice    | 	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
claimsservice    | 	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
claimsservice    | 	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:258) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:190) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:934) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:853) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:86) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:866) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1003) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:892) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:622) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:874) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:710) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:128) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:199) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:165) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:77) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:482) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:113) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:83) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:72) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:341) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:397) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1778) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:946) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:480) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:57) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at java.base/java.lang.Thread.run(Thread.java:1583) ~[na:na]
claimsservice    | 
claimsservice    | 2026-01-04T16:53:39.607Z ERROR 1 --- [Claims-Service] [nio-8083-exec-7] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: org.springframework.dao.InvalidDataAccessApiUsageException: Argument to query parameter has an incompatible type (java.time.LocalDate is not assignable to java.time.LocalDateTime)] with root cause
claimsservice    | 
claimsservice    | org.hibernate.query.QueryArgumentException: Argument to query parameter has an incompatible type (java.time.LocalDate is not assignable to java.time.LocalDateTime)
claimsservice    | 	at org.hibernate.query.spi.AbstractCommonQueryContract.setParameterValue(AbstractCommonQueryContract.java:881) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.spi.AbstractCommonQueryContract.setParameter(AbstractCommonQueryContract.java:907) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.spi.AbstractSelectionQuery.setParameter(AbstractSelectionQuery.java:651) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.sqm.internal.SqmQueryImpl.setParameter(SqmQueryImpl.java:1049) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.hibernate.query.sqm.internal.SqmQueryImpl.setParameter(SqmQueryImpl.java:109) ~[hibernate-core-7.2.0.Final.jar!/:7.2.0.Final]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$BindableQuery.setParameter(QueryParameterSetter.java:303) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$NamedOrIndexedQueryParameterSetter.setParameter(QueryParameterSetter.java:107) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.QueryParameterSetter$NamedOrIndexedQueryParameterSetter.setParameter(QueryParameterSetter.java:95) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bind(ParameterBinder.java:87) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bind(ParameterBinder.java:79) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.ParameterBinder.bindAndPrepare(ParameterBinder.java:100) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery$QueryPreparer.invokeBinding(PartTreeJpaQuery.java:368) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery$QueryPreparer.createQuery(PartTreeJpaQuery.java:250) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.doCreateQuery(PartTreeJpaQuery.java:125) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.createQuery(AbstractJpaQuery.java:264) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.JpaQueryExecution$PagedExecution.doExecute(JpaQueryExecution.java:285) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.JpaQueryExecution.execute(JpaQueryExecution.java:99) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.doExecute(AbstractJpaQuery.java:164) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.jpa.repository.query.AbstractJpaQuery.execute(AbstractJpaQuery.java:154) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:169) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:167) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:146) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69) ~[spring-data-commons-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:370) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:135) ~[spring-tx-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:137) ~[spring-data-jpa-4.0.1.jar!/:4.0.1]
claimsservice    | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:222) ~[spring-aop-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jdk.proxy2/jdk.proxy2.$Proxy149.findByClaimRequestDateBetweenOrderByRequestedAmountDesc(Unknown Source) ~[na:na]
claimsservice    | 	at org.example.claimsservice.service.Implementation.AnalyticServiceImpl.getTopHighValueClaimsLastMonth(AnalyticServiceImpl.java:43) ~[!/:0.0.1-SNAPSHOT]
claimsservice    | 	at org.example.claimsservice.controller.AnalyticController.getHighValueClaimsLastMonth(AnalyticController.java:40) ~[!/:0.0.1-SNAPSHOT]
claimsservice    | 	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
claimsservice    | 	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
claimsservice    | 	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:258) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:190) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:934) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:853) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:86) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:866) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1003) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:892) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:622) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:874) ~[spring-webmvc-7.0.2.jar!/:7.0.2]
claimsservice    | 	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:710) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:128) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:199) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.2.jar!/:7.0.2]
claimsservice    | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:165) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:77) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:482) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:113) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:83) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:72) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:341) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:397) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1778) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:946) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:480) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:57) ~[tomcat-embed-core-11.0.15.jar!/:na]
claimsservice    | 	at java.base/java.lang.Thread.run(Thread.java:1583) ~[na:na]
claimsservice    | 
mongo            | {"t":{"$date":"2026-01-04T16:54:18.017+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545658,"ts_usec":17684,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 9, snapshot max: 9 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
eureka           | 2026-01-04T16:54:23.444Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
mongo            | {"t":{"$date":"2026-01-04T16:55:18.031+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545718,"ts_usec":31514,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 10, snapshot max: 10 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
eureka           | 2026-01-04T16:55:23.444Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
mongo            | {"t":{"$date":"2026-01-04T16:56:18.039+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545778,"ts_usec":39056,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 11, snapshot max: 11 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
eureka           | 2026-01-04T16:56:23.444Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
providerservice  | 2026-01-04T16:56:58.385Z  INFO 1 --- [Provider-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
apigateway       | 2026-01-04T16:57:00.661Z  INFO 1 --- [Api-Gateway] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
emailservice     | 2026-01-04T16:57:01.412Z  INFO 1 --- [Email-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
identityservice  | 2026-01-04T16:57:01.480Z  INFO 1 --- [Identity-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
billingservice   | 2026-01-04T16:57:02.909Z  INFO 1 --- [Billing-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
claimsservice    | 2026-01-04T16:57:08.086Z  INFO 1 --- [Claims-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
policyservice    | 2026-01-04T16:57:08.880Z  INFO 1 --- [Policy-Service] [rap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
mongo            | {"t":{"$date":"2026-01-04T16:57:18.046+00:00"},"s":"I",  "c":"WTCHKPT",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":{"ts_sec":1767545838,"ts_usec":46513,"thread":"1:0x7f0f35c236c0","session_name":"WT_SESSION.checkpoint","category":"WT_VERB_CHECKPOINT_PROGRESS","log_id":1000000,"category_id":7,"verbose_level":"INFO","verbose_level_id":0,"msg":"saving checkpoint snapshot min: 12, snapshot max: 12 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 16017"}}}
eureka           | 2026-01-04T16:57:23.445Z  INFO 1 --- [Service-Registry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
identityservice  | 2026-01-04T16:57:37.712Z  INFO 1 --- [Identity-Service] [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
identityservice  | 2026-01-04T16:57:37.712Z  INFO 1 --- [Identity-Service] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
identityservice  | 2026-01-04T16:57:37.716Z  INFO 1 --- [Identity-Service] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 4 ms
mongo            | {"t":{"$date":"2026-01-04T16:57:37.935+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.21.0.12:41438","isLoadBalanced":false,"uuid":{"uuid":{"$uuid":"fe0c1ffb-aa97-487b-ad16-ed9704e7f702"}},"connectionId":5,"connectionCount":5}}
mongo            | {"t":{"$date":"2026-01-04T16:57:37.940+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn5","msg":"client metadata","attr":{"remote":"172.21.0.12:41438","client":"conn5","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}}}}
mongo            | {"t":{"$date":"2026-01-04T16:57:37.955+00:00"},"s":"I",  "c":"ACCESS",   "id":6788604, "ctx":"conn5","msg":"Auth metrics report","attr":{"metric":"acquireUser","micros":0}}
mongo            | {"t":{"$date":"2026-01-04T16:57:38.013+00:00"},"s":"I",  "c":"ACCESS",   "id":5286306, "ctx":"conn5","msg":"Successfully authenticated","attr":{"client":"172.21.0.12:41438","isSpeculative":true,"isClusterMember":false,"mechanism":"SCRAM-SHA-256","user":"root","db":"admin","result":0,"metrics":{"conversation_duration":{"micros":57764,"summary":{"0":{"step":1,"step_total":2,"duration_micros":84},"1":{"step":2,"step_total":2,"duration_micros":23}}}},"doc":{"driver":{"name":"mongo-java-driver|spring-boot|sync","version":"5.6.2"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"6.17.12-300.fc43.x86_64"},"platform":"Java/Eclipse Adoptium/21.0.9+10-LTS","env":{"container":{"runtime":"docker"}}},"extraInfo":{}}}
mongo            | {"t":{"$date":"2026-01-04T16:57:38.021+00:00"},"s":"I",  "c":"NETWORK",  "id":6788700, "ctx":"conn5","msg":"Received first command on ingress connection since session start or auth handshake","attr":{"elapsedMillis":7}}
apigateway       | 2026-01-04T16:57:38.228Z  INFO 1 --- [Api-Gateway] [or-http-epoll-2] o.e.a.filter.AuthenticationFilter        : AuthenticationFilter role: null
policyservice    | 2026-01-04T16:57:38.362Z  INFO 1 --- [Policy-Service] [nio-8081-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
policyservice    | 2026-01-04T16:57:38.362Z  INFO 1 --- [Policy-Service] [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
policyservice    | 2026-01-04T16:57:38.368Z  INFO 1 --- [Policy-Service] [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 6 ms
policyservice    | Hibernate: select p1_0.id,p1_0.coverage_amount,p1_0.description,p1_0.duration,p1_0.name,p1_0.premium_amount,p1_0.status from plan p1_0
apigateway       | 2026-01-04T16:57:39.771Z  INFO 1 --- [Api-Gateway] [or-http-epoll-2] o.e.a.filter.AuthenticationFilter        : AuthenticationFilter role: null
policyservice    | Hibernate: select p1_0.id,p1_0.coverage_amount,p1_0.description,p1_0.duration,p1_0.name,p1_0.premium_amount,p1_0.status from plan p1_0 where p1_0.id=?
policyservice    | Hibernate: select p1_0.id,p1_0.agent_id,p1_0.end_date,p1_0.plan_id,p1_0.remaining_coverage,p1_0.renewal_counter,p1_0.start_date,p1_0.status,p1_0.user_id from policy p1_0 where p1_0.user_id=? and p1_0.plan_id=?
apigateway       | 2026-01-04T16:57:42.401Z  INFO 1 --- [Api-Gateway] [or-http-epoll-2] o.e.a.filter.AuthenticationFilter        : AuthenticationFilter role: null
providerservice  | 2026-01-04T16:57:42.510Z  INFO 1 --- [Provider-Service] [nio-8082-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
providerservice  | 2026-01-04T16:57:42.510Z  INFO 1 --- [Provider-Service] [nio-8082-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
providerservice  | 2026-01-04T16:57:42.515Z  INFO 1 --- [Provider-Service] [nio-8082-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 5 ms
providerservice  | Hibernate: select hp1_0.id,hp1_0.hospital_id,hp1_0.network_type,hp1_0.plan_id from hospital_plan hp1_0 where hp1_0.plan_id=?
providerservice  | Hibernate: select h1_0.id,h1_0.city_name,h1_0.email,h1_0.hospital_name,h1_0.phone_number from hospital h1_0 where h1_0.id=?
apigateway       | 2026-01-04T16:57:45.665Z  INFO 1 --- [Api-Gateway] [or-http-epoll-2] o.e.a.filter.AuthenticationFilter        : AuthenticationFilter role: null
policyservice    | Hibernate: select p1_0.id,p1_0.coverage_amount,p1_0.description,p1_0.duration,p1_0.name,p1_0.premium_amount,p1_0.status from plan p1_0 where p1_0.id=?
policyservice    | Hibernate: select p1_0.id,p1_0.agent_id,p1_0.end_date,p1_0.plan_id,p1_0.remaining_coverage,p1_0.renewal_counter,p1_0.start_date,p1_0.status,p1_0.user_id from policy p1_0 where p1_0.user_id=? and p1_0.plan_id=?
